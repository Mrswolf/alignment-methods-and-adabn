{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib qt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings, copy, os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "import joblib\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, balanced_accuracy_score\n",
    "\n",
    "from brainda.datasets import (\n",
    "    PhysionetMI, BNCI2014001, Weibo2014, Cho2017)\n",
    "\n",
    "from brainda.paradigms import MotorImagery\n",
    "from brainda.algorithms.utils.model_selection import (\n",
    "    set_random_seeds,\n",
    "    generate_kfold_indices, match_kfold_indices)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import skorch\n",
    "from skorch.classifier import NeuralNetClassifier\n",
    "from skorch.helper import predefined_split\n",
    "from skorch.callbacks import (LRScheduler, EpochScoring, Checkpoint, Callback,\n",
    "                              TrainEndCheckpoint, LoadInitState, EarlyStopping)\n",
    "\n",
    "from brainda.algorithms.deep_learning import EEGNet, ShallowNet\n",
    "from braindecode.models import ShallowFBCSPNet, TIDNet, EEGNetv4\n",
    "from braindecode import EEGClassifier\n",
    "\n",
    "from brainda.algorithms.transfer_learning import MEKT\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPU devices: 1\n",
      "Current pytorch device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device_id = 0\n",
    "device = torch.device(\"cuda:{:d}\".format(device_id) if torch.cuda.is_available() else \"cpu\")\n",
    "if device != 'cpu':\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "print(\"Available GPU devices: {}\".format(torch.cuda.device_count()))\n",
    "print(\"Current pytorch device: {}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainda.algorithms.manifold.rpa import get_recenter, recenter\n",
    "\n",
    "def preprocessing(X, meta, k, indices, y=None, method='cnorm', no_split=False):\n",
    "    # remove mean\n",
    "    X = X - np.mean(X, axis=-1, keepdims=True)\n",
    "    \n",
    "    if method == 'cnorm':\n",
    "        X = X / np.std(X, axis=-1, keepdims=True)\n",
    "    elif method == 'tnorm':\n",
    "        X = X / np.std(X, axis= (-1, -2), keepdims=True)\n",
    "    elif method in ['riemann', 'euclid']:\n",
    "        # subject-level aligning\n",
    "        subjects = np.unique(meta['subject'])\n",
    "        for sub_id in subjects:\n",
    "            sub_meta = meta[meta['subject']==sub_id]\n",
    "            if no_split:\n",
    "                ind = sub_meta.index.to_numpy()\n",
    "                iM12 = get_recenter(\n",
    "                    X[ind],\n",
    "                    cov_method='lwf',\n",
    "                    mean_method=method)\n",
    "                X[ind] = recenter(X[ind], iM12)\n",
    "            else:\n",
    "                train_ind, validate_ind, test_ind = match_kfold_indices(k, sub_meta, indices)\n",
    "                iM12 = get_recenter(\n",
    "                    X[np.concatenate((train_ind, validate_ind))],\n",
    "                    cov_method='lwf', \n",
    "                    mean_method=method)\n",
    "                X[train_ind] = recenter(X[train_ind], iM12)\n",
    "                X[validate_ind] = recenter(X[validate_ind], iM12)\n",
    "                X[test_ind] = recenter(X[test_ind], iM12)      \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_hook(raw, caches, verbose=False):\n",
    "    raw.filter(4, 40, l_trans_bandwidth=2, h_trans_bandwidth=5, phase='zero-double')\n",
    "    return raw, caches\n",
    "\n",
    "class NeuralNetClassifierNoLog(NeuralNetClassifier):\n",
    "    def get_loss(self, y_pred, y_true, *args, **kwargs):\n",
    "        return super(NeuralNetClassifier, self).get_loss(y_pred, y_true, *args, **kwargs)\n",
    "\n",
    "def make_model(model_name, n_channels, n_samples, n_classes):\n",
    "    set_random_seeds(64)\n",
    "    if model_name == 'eegnetv4':\n",
    "        model = EEGNetv4(n_channels, n_classes, \n",
    "                    input_window_samples=n_samples, \n",
    "                    F1=8,\n",
    "                    D=2,\n",
    "                    F2=16,\n",
    "                    kernel_length=64,\n",
    "                    drop_prob=0.5)\n",
    "    elif model_name == 'shallowfbcspnet':\n",
    "        model = ShallowFBCSPNet(n_channels, n_classes,\n",
    "                    input_window_samples=n_samples,\n",
    "                    n_filters_time=40,\n",
    "                    filter_time_length=13,\n",
    "                    n_filters_spat=20,\n",
    "                    pool_time_length=37,\n",
    "                    pool_time_stride=7,\n",
    "                    final_conv_length='auto',\n",
    "                    drop_prob=0.5)\n",
    "    elif model_name == 'tidnet':\n",
    "        model = TIDNet(n_channels, n_classes, \n",
    "                    input_window_samples=n_samples,\n",
    "                    s_growth=24,\n",
    "                    t_filters=32, \n",
    "                    temp_layers=2, \n",
    "                    spat_layers=2, \n",
    "                    pooling=15, \n",
    "                    temp_span=0.05, \n",
    "                    bottleneck=3)\n",
    "    elif model_name == 'eegnet':\n",
    "        model = EEGNet(n_channels, n_samples, n_classes,\n",
    "                    time_kernel=(8, (1, 64), (1, 1)),\n",
    "                    D=2,\n",
    "                    pool_kernel1=((1, 4), (1, 4)),\n",
    "                    separa_kernel=(16, (1, 16), (1, 1)),\n",
    "                    pool_kernel2=((1, 8), (1, 8)),\n",
    "                    depthwise_norm_rate=1,\n",
    "                    fc_norm_rate=0.25,\n",
    "                    dropout_rate=0.5)\n",
    "    elif model_name == 'shallownet':\n",
    "        model = ShallowNet(n_channels, n_samples, n_classes,\n",
    "                    n_time_filters=40,\n",
    "                    time_kernel=13,\n",
    "                    n_space_filters=20,\n",
    "                    pool_kernel=37,\n",
    "                    pool_stride=7,\n",
    "                    dropout_rate=0.5)\n",
    "        \n",
    "    return model\n",
    "    \n",
    "def network_training(model_name, dataset, selected_channels, srate, duration, events,\n",
    "    kfold=5,\n",
    "    save_folder='eegnet',\n",
    "    batch_size=256, lr=1e-2, max_epochs=400, T_max=400,\n",
    "    criterion=nn.NLLLoss, optimizer=optim.Adam,\n",
    "    preprocess_methods=['raw'],\n",
    "    force_update=False,\n",
    "    verbose=False):\n",
    "    \n",
    "    for preprocess_method in preprocess_methods:\n",
    "        ckp_dirname = 'runs_{}'.format(model_name)\n",
    "        os.makedirs(save_folder, exist_ok=True)\n",
    "        save_file = os.path.join(\n",
    "            save_folder, \n",
    "            \"{}-{}-{}classes.joblib\".format(\n",
    "                dataset.dataset_code, \n",
    "                '{}-{}'.format(model_name, preprocess_method), \n",
    "                len(events)))\n",
    "        if not force_update and os.path.exists(save_file):\n",
    "            kfold_accs = joblib.load(save_file)['kfold_accs']\n",
    "            print(\"Dataset:{} {} Acc: {:.4f}\".format(\n",
    "                dataset.dataset_code,\n",
    "                '{}-{}'.format(model_name, preprocess_method),\n",
    "                np.mean(kfold_accs)))\n",
    "            continue\n",
    "        \n",
    "        start_t = dataset.events['left_hand'][1][0]\n",
    "        if start_t+ duration > dataset.events['left_hand'][1][1]:\n",
    "            print(\"Warning: the current dataset avaliable trial duration is not long enough.\")\n",
    "        paradigm = MotorImagery(\n",
    "            channels=selected_channels, \n",
    "            srate=srate, \n",
    "            intervals=[(start_t, start_t + duration)], \n",
    "            events=events)\n",
    "        event_id = [dataset.events[e][0] for e in events]\n",
    "        paradigm.register_raw_hook(raw_hook)\n",
    "        X, y, meta = paradigm.get_data(\n",
    "            dataset, \n",
    "            subjects=dataset.subjects, \n",
    "            return_concat=True, \n",
    "            verbose=False)\n",
    "        y = label_encoder(y, event_id)\n",
    "        labels = np.unique(y)\n",
    "\n",
    "        set_random_seeds(38)\n",
    "        indices = generate_kfold_indices(meta, kfold=kfold)\n",
    "        \n",
    "        \n",
    "        n_trials, n_channels, n_samples = X.shape\n",
    "        n_classes = len(labels)\n",
    "        x_dtype, y_dtype = torch.float, torch.long\n",
    "        model = make_model(model_name, n_channels, n_samples, n_classes)\n",
    "        initial_state = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "        kfold_accs, kfold_cms = [], []\n",
    "        model_states = []\n",
    "\n",
    "        set_random_seeds(42)\n",
    "        for k in range(kfold):\n",
    "            filterX = np.copy(X)\n",
    "            filterY = np.copy(y)\n",
    "\n",
    "            filterX = preprocessing(filterX, meta, k, indices, method=preprocess_method)\n",
    "\n",
    "            train_ind, validate_ind, test_ind = match_kfold_indices(k, meta, indices)\n",
    "            trainX, trainy = filterX[train_ind], filterY[train_ind]\n",
    "            validateX, validatey = filterX[validate_ind], filterY[validate_ind]\n",
    "            testX, testy = filterX[test_ind], filterY[test_ind]\n",
    "\n",
    "            trainX, validateX, testX = generate_tensors(trainX, validateX, testX, dtype=x_dtype)\n",
    "            trainy, validatey, testy = generate_tensors(trainy, validatey, testy, dtype=y_dtype)\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "            ckp = Checkpoint(dirname=ckp_dirname)\n",
    "            train_end_ckp = TrainEndCheckpoint(dirname=ckp_dirname)\n",
    "            estopper = EarlyStopping(patience=50)\n",
    "\n",
    "            model.load_state_dict(copy.deepcopy(initial_state))\n",
    "            train_split = predefined_split(\n",
    "                skorch.dataset.Dataset(\n",
    "                    validateX, validatey))\n",
    "\n",
    "            net = NeuralNetClassifierNoLog(model,\n",
    "                    criterion=criterion,\n",
    "                    optimizer=optimizer,\n",
    "                    batch_size=batch_size, \n",
    "                    lr=lr, \n",
    "                    max_epochs=max_epochs,\n",
    "                    device=device,\n",
    "                    train_split=train_split,\n",
    "                    iterator_train__shuffle=True,\n",
    "                    callbacks=[\n",
    "                        ('train_acc', EpochScoring('accuracy', \n",
    "                                                   name='train_acc', \n",
    "                                                   on_train=True, \n",
    "                                                   lower_is_better=False)),\n",
    "                         ('lr_scheduler', LRScheduler('CosineAnnealingLR', T_max=T_max - 1)),\n",
    "                        estopper,\n",
    "                        ckp,\n",
    "                        train_end_ckp\n",
    "                    ],\n",
    "                    verbose=verbose)\n",
    "\n",
    "            net.fit(trainX, y=trainy)\n",
    "            net.load_params(checkpoint=ckp)\n",
    "            model_states.append(copy.deepcopy(net.module_.state_dict()))\n",
    "\n",
    "            # test set\n",
    "            pred_labels = net.predict(testX)\n",
    "            true_labels = testy.numpy()\n",
    "            cm = confusion_matrix(true_labels, pred_labels, labels=labels, normalize='true')\n",
    "            kfold_accs.append(balanced_accuracy_score(true_labels, pred_labels))\n",
    "            kfold_cms.append(cm)\n",
    "\n",
    "        print(\"Dataset:{} {} Acc: {:.4f}\".format(\n",
    "            dataset.dataset_code,\n",
    "            '{}-{}'.format(model_name, preprocess_method),\n",
    "            np.mean(kfold_accs)))\n",
    "        joblib.dump({\n",
    "            'model_states': model_states, \n",
    "            'kfold_accs': kfold_accs, 'kfold_cms': kfold_cms}, \n",
    "            save_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:bnci2014001 tidnet-raw Acc: 0.6131\n",
      "Dataset:bnci2014001 tidnet-cnorm Acc: 0.5657\n",
      "Dataset:bnci2014001 tidnet-tnorm Acc: 0.6107\n",
      "Dataset:bnci2014001 tidnet-euclid Acc: 0.7872\n",
      "Dataset:bnci2014001 tidnet-riemann Acc: 0.8007\n",
      "Dataset:eegbci tidnet-raw Acc: 0.5478\n",
      "Dataset:eegbci tidnet-cnorm Acc: 0.5313\n",
      "Dataset:eegbci tidnet-tnorm Acc: 0.5629\n",
      "Dataset:eegbci tidnet-euclid Acc: 0.6278\n",
      "Dataset:eegbci tidnet-riemann Acc: 0.6358\n",
      "Dataset:weibo2014 tidnet-raw Acc: 0.6285\n",
      "Dataset:weibo2014 tidnet-cnorm Acc: 0.5519\n",
      "Dataset:weibo2014 tidnet-tnorm Acc: 0.6127\n",
      "Dataset:weibo2014 tidnet-euclid Acc: 0.6987\n",
      "Dataset:weibo2014 tidnet-riemann Acc: 0.7038\n",
      "Dataset:cho2017 tidnet-raw Acc: 0.5438\n",
      "Dataset:cho2017 tidnet-cnorm Acc: 0.5351\n",
      "Dataset:cho2017 tidnet-tnorm Acc: 0.5449\n",
      "Dataset:cho2017 tidnet-euclid Acc: 0.6338\n",
      "Dataset:cho2017 tidnet-riemann Acc: 0.6294\n"
     ]
    }
   ],
   "source": [
    "srate = 128\n",
    "datasets = [BNCI2014001(), PhysionetMI(), Weibo2014(), Cho2017()]\n",
    "selected_channels = ['FZ', 'FC3', 'FC1', 'FCZ', 'FC2', 'FC4', 'C5', 'C3', 'C1', 'CZ', 'C2', 'C4', 'C6', 'CP3', 'CP1', 'CPZ', 'CP2', 'CP4', 'P1', 'PZ', 'P2', 'POZ']\n",
    "duration = 3 # seconds\n",
    "events = ['left_hand', 'right_hand']\n",
    "preprocess_methods = ['raw', 'cnorm', 'tnorm', 'euclid', 'riemann']\n",
    "kfold = 5\n",
    "\n",
    "model_names = ['shallownet', 'eegnet', 'shallowfbcspnet', 'eegnetv4', 'tident']\n",
    "lrs = [0.0625 * 0.01, 1e-2, 0.0625 * 0.01, 1e-2, 1e-3]\n",
    "\n",
    "for i, model_name in enumerate(model_names):\n",
    "    if model_name in ['shallownet', 'eegnet']:\n",
    "        criterion = nn.CrossEntropyLoss\n",
    "    else:\n",
    "        criterion = nn.NLLLoss\n",
    "        \n",
    "    for dataset in datasets:\n",
    "        network_training(model_name, dataset, selected_channels, srate, duration, events,\n",
    "            kfold=kfold, \n",
    "            save_folder=model_name, \n",
    "            batch_size=256, lr=lrs[i], max_epochs=200, T_max=200,\n",
    "            criterion=criterion,\n",
    "            preprocess_methods=preprocess_methods,\n",
    "            force_update=False,\n",
    "            verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-dataset Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchnorm_pre_forward_hook(self, input):\n",
    "    old_training_state = self.training\n",
    "    self.eval()\n",
    "    # global AdaBN\n",
    "    with torch.no_grad():\n",
    "        self.running_mean.data.zero_()\n",
    "        self.running_mean.data.add_(torch.mean(input[0], dim=(0, 2, 3)))\n",
    "        self.running_var.data.zero_()\n",
    "        self.running_var.data.add_(torch.var(input[0], dim=(0, 2, 3)))\n",
    "    if old_training_state:\n",
    "        self.train()\n",
    "\n",
    "def cross_dataset_network_predict(\n",
    "    model_name, source_dataset, target_dataset, selected_channels, srate, duration, events,\n",
    "    kfold=5,\n",
    "    save_folder='eegnet',\n",
    "    preprocess_methods=['raw'],\n",
    "    use_adabn=False,\n",
    "    force_update=False):\n",
    "    \n",
    "    for preprocess_method in preprocess_methods:\n",
    "        model_name_str = '{}-{}'.format(model_name, preprocess_method)\n",
    "        \n",
    "        model_file = os.path.join(\n",
    "            save_folder, \n",
    "            \"{}-{}-{}classes.joblib\".format(\n",
    "                source_dataset.dataset_code, \n",
    "                model_name_str, \n",
    "                len(events)))\n",
    "        \n",
    "        if use_adabn:\n",
    "            save_file = os.path.join(\n",
    "                save_folder,\n",
    "                \"{}->{}-{}-{}classes.joblib\".format(\n",
    "                    source_dataset.dataset_code,\n",
    "                    target_dataset.dataset_code,\n",
    "                    model_name_str+'-adabn',\n",
    "                    len(events)))\n",
    "        else:\n",
    "            save_file = os.path.join(\n",
    "                save_folder,\n",
    "                \"{}->{}-{}-{}classes.joblib\".format(\n",
    "                    source_dataset.dataset_code,\n",
    "                    target_dataset.dataset_code,\n",
    "                    model_name_str,\n",
    "                    len(events)))\n",
    "        \n",
    "        if not force_update and os.path.exists(save_file):\n",
    "            kfold_accs = joblib.load(save_file)['kfold_accs']\n",
    "            print(\"Source: {} Target: {} {} Acc: {:.4f}\".format(\n",
    "                source_dataset.dataset_code,\n",
    "                target_dataset.dataset_code,\n",
    "                model_name_str+'-adabn' if use_adabn else model_name_str,\n",
    "                np.mean(kfold_accs)))\n",
    "            continue\n",
    "            \n",
    "        start_t = target_dataset.events['left_hand'][1][0]\n",
    "        if start_t+ duration > target_dataset.events['left_hand'][1][1]:\n",
    "            print(\"Warning: the current dataset avaliable trial duration is not long enough.\")\n",
    "        paradigm = MotorImagery(\n",
    "            channels=selected_channels, \n",
    "            srate=srate, \n",
    "            intervals=[(start_t, start_t + duration)], \n",
    "            events=events)\n",
    "        event_id = [target_dataset.events[e][0] for e in events]\n",
    "        paradigm.register_raw_hook(raw_hook)\n",
    "\n",
    "        X, y, meta = paradigm.get_data(\n",
    "            target_dataset, \n",
    "            subjects=target_dataset.subjects, \n",
    "            return_concat=True, \n",
    "            verbose=False)\n",
    "        y = label_encoder(y, event_id)\n",
    "        labels = np.unique(y)\n",
    "\n",
    "        set_random_seeds(38)\n",
    "        indices = generate_kfold_indices(meta, kfold=kfold)\n",
    "            \n",
    "        \n",
    "        model_states = joblib.load(model_file)['model_states']\n",
    "        \n",
    "        n_trials, n_channels, n_samples = X.shape\n",
    "        n_classes = len(labels)\n",
    "        x_dtype, y_dtype = torch.float, torch.long\n",
    "        model = make_model(model_name, n_channels, n_samples, n_classes)\n",
    "        if use_adabn:\n",
    "            handles = []\n",
    "            for module in model.modules():\n",
    "                if 'BatchNorm' in module.__class__.__name__:\n",
    "                    handles.append(\n",
    "                        module.register_forward_pre_hook(batchnorm_pre_forward_hook))\n",
    "\n",
    "        kfold_accs, kfold_cms = [], []\n",
    " \n",
    "        set_random_seeds(42)\n",
    "        for k in range(kfold):\n",
    "            model.load_state_dict(copy.deepcopy(model_states[k]))\n",
    "            model.eval()\n",
    "            \n",
    "            filterX = np.copy(X)\n",
    "            filterY = np.copy(y)\n",
    "            \n",
    "            if source_dataset.dataset_code != target_dataset.dataset_code:\n",
    "                # make k and indices useless\n",
    "                filterX = preprocessing(filterX, meta, None, None,\n",
    "                            method=preprocess_method,\n",
    "                            no_split=True)\n",
    "            else:\n",
    "                filterX = preprocessing(filterX, meta, k, indices,\n",
    "                            method=preprocess_method,\n",
    "                            no_split=False)\n",
    "            \n",
    "            sub_accs, sub_cms = [], []\n",
    "            for sub_id in target_dataset.subjects:\n",
    "                if source_dataset.dataset_code != target_dataset.dataset_code:\n",
    "                    test_ind = meta[meta['subject']==sub_id].index.to_numpy()\n",
    "                else:\n",
    "                    _, _, test_ind = match_kfold_indices(k, meta[meta['subject']==sub_id], indices)\n",
    "                testX, testy = filterX[test_ind], filterY[test_ind]\n",
    "\n",
    "                testX = generate_tensors(testX, dtype=x_dtype)\n",
    "                testy = generate_tensors(testy, dtype=y_dtype)\n",
    "                \n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "                output = model(testX)\n",
    "                pred_labels = torch.argmax(output, dim=1).detach().numpy()\n",
    "                true_labels = testy.numpy()\n",
    "                cm = confusion_matrix(true_labels, pred_labels, labels=labels, normalize='true')\n",
    "                sub_accs.append(balanced_accuracy_score(true_labels, pred_labels))\n",
    "                sub_cms.append(cm)\n",
    "            kfold_accs.append(sub_accs)\n",
    "            kfold_cms.append(sub_cms)\n",
    "\n",
    "        print(\"Source: {} Target: {} {} Acc: {:.4f}\".format(\n",
    "            source_dataset.dataset_code,\n",
    "            target_dataset.dataset_code,\n",
    "            model_name_str+'-adabn' if use_adabn else model_name_str,\n",
    "            np.mean(kfold_accs)))\n",
    "        joblib.dump({\n",
    "            'kfold_accs': kfold_accs, 'kfold_cms': kfold_cms}, \n",
    "            save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: bnci2014001 Target: bnci2014001 shallownet-raw Acc: 0.8165\n",
      "Source: bnci2014001 Target: bnci2014001 shallownet-cnorm Acc: 0.8081\n",
      "Source: bnci2014001 Target: bnci2014001 shallownet-tnorm Acc: 0.7987\n",
      "Source: bnci2014001 Target: bnci2014001 shallownet-euclid Acc: 0.8634\n",
      "Source: bnci2014001 Target: bnci2014001 shallownet-riemann Acc: 0.8611\n",
      "Source: bnci2014001 Target: eegbci shallownet-raw Acc: 0.6094\n",
      "Source: bnci2014001 Target: eegbci shallownet-cnorm Acc: 0.6132\n",
      "Source: bnci2014001 Target: eegbci shallownet-tnorm Acc: 0.6172\n",
      "Source: bnci2014001 Target: eegbci shallownet-euclid Acc: 0.6384\n",
      "Source: bnci2014001 Target: eegbci shallownet-riemann Acc: 0.6285\n",
      "Source: bnci2014001 Target: weibo2014 shallownet-raw Acc: 0.6279\n",
      "Source: bnci2014001 Target: weibo2014 shallownet-cnorm Acc: 0.6328\n",
      "Source: bnci2014001 Target: weibo2014 shallownet-tnorm Acc: 0.6381\n",
      "Source: bnci2014001 Target: weibo2014 shallownet-euclid Acc: 0.7003\n",
      "Source: bnci2014001 Target: weibo2014 shallownet-riemann Acc: 0.6897\n",
      "Source: bnci2014001 Target: cho2017 shallownet-raw Acc: 0.5592\n",
      "Source: bnci2014001 Target: cho2017 shallownet-cnorm Acc: 0.5730\n",
      "Source: bnci2014001 Target: cho2017 shallownet-tnorm Acc: 0.5896\n",
      "Source: bnci2014001 Target: cho2017 shallownet-euclid Acc: 0.5842\n",
      "Source: bnci2014001 Target: cho2017 shallownet-riemann Acc: 0.5823\n",
      "Source: eegbci Target: bnci2014001 shallownet-raw Acc: 0.7465\n",
      "Source: eegbci Target: bnci2014001 shallownet-cnorm Acc: 0.6423\n",
      "Source: eegbci Target: bnci2014001 shallownet-tnorm Acc: 0.7080\n",
      "Source: eegbci Target: bnci2014001 shallownet-euclid Acc: 0.7283\n",
      "Source: eegbci Target: bnci2014001 shallownet-riemann Acc: 0.7323\n",
      "Source: eegbci Target: eegbci shallownet-raw Acc: 0.7131\n",
      "Source: eegbci Target: eegbci shallownet-cnorm Acc: 0.6947\n",
      "Source: eegbci Target: eegbci shallownet-tnorm Acc: 0.6967\n",
      "Source: eegbci Target: eegbci shallownet-euclid Acc: 0.6755\n",
      "Source: eegbci Target: eegbci shallownet-riemann Acc: 0.6846\n",
      "Source: eegbci Target: weibo2014 shallownet-raw Acc: 0.6680\n",
      "Source: eegbci Target: weibo2014 shallownet-cnorm Acc: 0.6054\n",
      "Source: eegbci Target: weibo2014 shallownet-tnorm Acc: 0.6567\n",
      "Source: eegbci Target: weibo2014 shallownet-euclid Acc: 0.7052\n",
      "Source: eegbci Target: weibo2014 shallownet-riemann Acc: 0.7036\n",
      "Source: eegbci Target: cho2017 shallownet-raw Acc: 0.6050\n",
      "Source: eegbci Target: cho2017 shallownet-cnorm Acc: 0.5641\n",
      "Source: eegbci Target: cho2017 shallownet-tnorm Acc: 0.5897\n",
      "Source: eegbci Target: cho2017 shallownet-euclid Acc: 0.6099\n",
      "Source: eegbci Target: cho2017 shallownet-riemann Acc: 0.6125\n",
      "Source: weibo2014 Target: bnci2014001 shallownet-raw Acc: 0.6326\n",
      "Source: weibo2014 Target: bnci2014001 shallownet-cnorm Acc: 0.6302\n",
      "Source: weibo2014 Target: bnci2014001 shallownet-tnorm Acc: 0.6157\n",
      "Source: weibo2014 Target: bnci2014001 shallownet-euclid Acc: 0.6894\n",
      "Source: weibo2014 Target: bnci2014001 shallownet-riemann Acc: 0.6887\n",
      "Source: weibo2014 Target: eegbci shallownet-raw Acc: 0.5830\n",
      "Source: weibo2014 Target: eegbci shallownet-cnorm Acc: 0.5768\n",
      "Source: weibo2014 Target: eegbci shallownet-tnorm Acc: 0.6031\n",
      "Source: weibo2014 Target: eegbci shallownet-euclid Acc: 0.6228\n",
      "Source: weibo2014 Target: eegbci shallownet-riemann Acc: 0.6216\n",
      "Source: weibo2014 Target: weibo2014 shallownet-raw Acc: 0.7223\n",
      "Source: weibo2014 Target: weibo2014 shallownet-cnorm Acc: 0.7021\n",
      "Source: weibo2014 Target: weibo2014 shallownet-tnorm Acc: 0.7063\n",
      "Source: weibo2014 Target: weibo2014 shallownet-euclid Acc: 0.7636\n",
      "Source: weibo2014 Target: weibo2014 shallownet-riemann Acc: 0.7704\n",
      "Source: weibo2014 Target: cho2017 shallownet-raw Acc: 0.5548\n",
      "Source: weibo2014 Target: cho2017 shallownet-cnorm Acc: 0.5685\n",
      "Source: weibo2014 Target: cho2017 shallownet-tnorm Acc: 0.5683\n",
      "Source: weibo2014 Target: cho2017 shallownet-euclid Acc: 0.6175\n",
      "Source: weibo2014 Target: cho2017 shallownet-riemann Acc: 0.6171\n",
      "Source: cho2017 Target: bnci2014001 shallownet-raw Acc: 0.5338\n",
      "Source: cho2017 Target: bnci2014001 shallownet-cnorm Acc: 0.6352\n",
      "Source: cho2017 Target: bnci2014001 shallownet-tnorm Acc: 0.6290\n",
      "Source: cho2017 Target: bnci2014001 shallownet-euclid Acc: 0.7037\n",
      "Source: cho2017 Target: bnci2014001 shallownet-riemann Acc: 0.7073\n",
      "Source: cho2017 Target: eegbci shallownet-raw Acc: 0.5666\n",
      "Source: cho2017 Target: eegbci shallownet-cnorm Acc: 0.6011\n",
      "Source: cho2017 Target: eegbci shallownet-tnorm Acc: 0.5880\n",
      "Source: cho2017 Target: eegbci shallownet-euclid Acc: 0.6486\n",
      "Source: cho2017 Target: eegbci shallownet-riemann Acc: 0.6504\n",
      "Source: cho2017 Target: weibo2014 shallownet-raw Acc: 0.5509\n",
      "Source: cho2017 Target: weibo2014 shallownet-cnorm Acc: 0.6513\n",
      "Source: cho2017 Target: weibo2014 shallownet-tnorm Acc: 0.6408\n",
      "Source: cho2017 Target: weibo2014 shallownet-euclid Acc: 0.7349\n",
      "Source: cho2017 Target: weibo2014 shallownet-riemann Acc: 0.7340\n",
      "Source: cho2017 Target: cho2017 shallownet-raw Acc: 0.7010\n",
      "Source: cho2017 Target: cho2017 shallownet-cnorm Acc: 0.6787\n",
      "Source: cho2017 Target: cho2017 shallownet-tnorm Acc: 0.6949\n",
      "Source: cho2017 Target: cho2017 shallownet-euclid Acc: 0.6981\n",
      "Source: cho2017 Target: cho2017 shallownet-riemann Acc: 0.6993\n",
      "Source: bnci2014001 Target: bnci2014001 eegnet-raw Acc: 0.8275\n",
      "Source: bnci2014001 Target: bnci2014001 eegnet-cnorm Acc: 0.8289\n",
      "Source: bnci2014001 Target: bnci2014001 eegnet-tnorm Acc: 0.8241\n",
      "Source: bnci2014001 Target: bnci2014001 eegnet-euclid Acc: 0.8921\n",
      "Source: bnci2014001 Target: bnci2014001 eegnet-riemann Acc: 0.8940\n",
      "Source: bnci2014001 Target: eegbci eegnet-raw Acc: 0.6292\n",
      "Source: bnci2014001 Target: eegbci eegnet-cnorm Acc: 0.6188\n",
      "Source: bnci2014001 Target: eegbci eegnet-tnorm Acc: 0.6264\n",
      "Source: bnci2014001 Target: eegbci eegnet-euclid Acc: 0.6549\n",
      "Source: bnci2014001 Target: eegbci eegnet-riemann Acc: 0.6546\n",
      "Source: bnci2014001 Target: weibo2014 eegnet-raw Acc: 0.6385\n",
      "Source: bnci2014001 Target: weibo2014 eegnet-cnorm Acc: 0.6416\n",
      "Source: bnci2014001 Target: weibo2014 eegnet-tnorm Acc: 0.6402\n",
      "Source: bnci2014001 Target: weibo2014 eegnet-euclid Acc: 0.6871\n",
      "Source: bnci2014001 Target: weibo2014 eegnet-riemann Acc: 0.6785\n",
      "Source: bnci2014001 Target: cho2017 eegnet-raw Acc: 0.5941\n",
      "Source: bnci2014001 Target: cho2017 eegnet-cnorm Acc: 0.5720\n",
      "Source: bnci2014001 Target: cho2017 eegnet-tnorm Acc: 0.5976\n",
      "Source: bnci2014001 Target: cho2017 eegnet-euclid Acc: 0.5989\n",
      "Source: bnci2014001 Target: cho2017 eegnet-riemann Acc: 0.5949\n",
      "Source: eegbci Target: bnci2014001 eegnet-raw Acc: 0.6765\n",
      "Source: eegbci Target: bnci2014001 eegnet-cnorm Acc: 0.7100\n",
      "Source: eegbci Target: bnci2014001 eegnet-tnorm Acc: 0.7150\n",
      "Source: eegbci Target: bnci2014001 eegnet-euclid Acc: 0.7704\n",
      "Source: eegbci Target: bnci2014001 eegnet-riemann Acc: 0.7700\n",
      "Source: eegbci Target: eegbci eegnet-raw Acc: 0.6352\n",
      "Source: eegbci Target: eegbci eegnet-cnorm Acc: 0.6405\n",
      "Source: eegbci Target: eegbci eegnet-tnorm Acc: 0.6642\n",
      "Source: eegbci Target: eegbci eegnet-euclid Acc: 0.7123\n",
      "Source: eegbci Target: eegbci eegnet-riemann Acc: 0.7125\n",
      "Source: eegbci Target: weibo2014 eegnet-raw Acc: 0.5989\n",
      "Source: eegbci Target: weibo2014 eegnet-cnorm Acc: 0.6325\n",
      "Source: eegbci Target: weibo2014 eegnet-tnorm Acc: 0.6644\n",
      "Source: eegbci Target: weibo2014 eegnet-euclid Acc: 0.7028\n",
      "Source: eegbci Target: weibo2014 eegnet-riemann Acc: 0.7211\n",
      "Source: eegbci Target: cho2017 eegnet-raw Acc: 0.5592\n",
      "Source: eegbci Target: cho2017 eegnet-cnorm Acc: 0.5776\n",
      "Source: eegbci Target: cho2017 eegnet-tnorm Acc: 0.5788\n",
      "Source: eegbci Target: cho2017 eegnet-euclid Acc: 0.6268\n",
      "Source: eegbci Target: cho2017 eegnet-riemann Acc: 0.6286\n",
      "Source: weibo2014 Target: bnci2014001 eegnet-raw Acc: 0.6498\n",
      "Source: weibo2014 Target: bnci2014001 eegnet-cnorm Acc: 0.6398\n",
      "Source: weibo2014 Target: bnci2014001 eegnet-tnorm Acc: 0.6333\n",
      "Source: weibo2014 Target: bnci2014001 eegnet-euclid Acc: 0.6911\n",
      "Source: weibo2014 Target: bnci2014001 eegnet-riemann Acc: 0.6906\n",
      "Source: weibo2014 Target: eegbci eegnet-raw Acc: 0.6032\n",
      "Source: weibo2014 Target: eegbci eegnet-cnorm Acc: 0.5748\n",
      "Source: weibo2014 Target: eegbci eegnet-tnorm Acc: 0.5985\n",
      "Source: weibo2014 Target: eegbci eegnet-euclid Acc: 0.6379\n",
      "Source: weibo2014 Target: eegbci eegnet-riemann Acc: 0.6336\n",
      "Source: weibo2014 Target: weibo2014 eegnet-raw Acc: 0.7014\n",
      "Source: weibo2014 Target: weibo2014 eegnet-cnorm Acc: 0.6857\n",
      "Source: weibo2014 Target: weibo2014 eegnet-tnorm Acc: 0.7035\n",
      "Source: weibo2014 Target: weibo2014 eegnet-euclid Acc: 0.7638\n",
      "Source: weibo2014 Target: weibo2014 eegnet-riemann Acc: 0.7666\n",
      "Source: weibo2014 Target: cho2017 eegnet-raw Acc: 0.5754\n",
      "Source: weibo2014 Target: cho2017 eegnet-cnorm Acc: 0.5702\n",
      "Source: weibo2014 Target: cho2017 eegnet-tnorm Acc: 0.5728\n",
      "Source: weibo2014 Target: cho2017 eegnet-euclid Acc: 0.6319\n",
      "Source: weibo2014 Target: cho2017 eegnet-riemann Acc: 0.6283\n",
      "Source: cho2017 Target: bnci2014001 eegnet-raw Acc: 0.5053\n",
      "Source: cho2017 Target: bnci2014001 eegnet-cnorm Acc: 0.6562\n",
      "Source: cho2017 Target: bnci2014001 eegnet-tnorm Acc: 0.6651\n",
      "Source: cho2017 Target: bnci2014001 eegnet-euclid Acc: 0.6917\n",
      "Source: cho2017 Target: bnci2014001 eegnet-riemann Acc: 0.6969\n",
      "Source: cho2017 Target: eegbci eegnet-raw Acc: 0.5278\n",
      "Source: cho2017 Target: eegbci eegnet-cnorm Acc: 0.5871\n",
      "Source: cho2017 Target: eegbci eegnet-tnorm Acc: 0.6034\n",
      "Source: cho2017 Target: eegbci eegnet-euclid Acc: 0.6519\n",
      "Source: cho2017 Target: eegbci eegnet-riemann Acc: 0.6494\n",
      "Source: cho2017 Target: weibo2014 eegnet-raw Acc: 0.5090\n",
      "Source: cho2017 Target: weibo2014 eegnet-cnorm Acc: 0.6128\n",
      "Source: cho2017 Target: weibo2014 eegnet-tnorm Acc: 0.6398\n",
      "Source: cho2017 Target: weibo2014 eegnet-euclid Acc: 0.7149\n",
      "Source: cho2017 Target: weibo2014 eegnet-riemann Acc: 0.7124\n",
      "Source: cho2017 Target: cho2017 eegnet-raw Acc: 0.6877\n",
      "Source: cho2017 Target: cho2017 eegnet-cnorm Acc: 0.6880\n",
      "Source: cho2017 Target: cho2017 eegnet-tnorm Acc: 0.6841\n",
      "Source: cho2017 Target: cho2017 eegnet-euclid Acc: 0.7193\n",
      "Source: cho2017 Target: cho2017 eegnet-riemann Acc: 0.7245\n",
      "Source: bnci2014001 Target: bnci2014001 shallowfbcspnet-raw Acc: 0.8203\n",
      "Source: bnci2014001 Target: bnci2014001 shallowfbcspnet-cnorm Acc: 0.7982\n",
      "Source: bnci2014001 Target: bnci2014001 shallowfbcspnet-tnorm Acc: 0.7998\n",
      "Source: bnci2014001 Target: bnci2014001 shallowfbcspnet-euclid Acc: 0.8363\n",
      "Source: bnci2014001 Target: bnci2014001 shallowfbcspnet-riemann Acc: 0.8367\n",
      "Source: bnci2014001 Target: eegbci shallowfbcspnet-raw Acc: 0.6074\n",
      "Source: bnci2014001 Target: eegbci shallowfbcspnet-cnorm Acc: 0.5993\n",
      "Source: bnci2014001 Target: eegbci shallowfbcspnet-tnorm Acc: 0.6140\n",
      "Source: bnci2014001 Target: eegbci shallowfbcspnet-euclid Acc: 0.6430\n",
      "Source: bnci2014001 Target: eegbci shallowfbcspnet-riemann Acc: 0.6371\n",
      "Source: bnci2014001 Target: weibo2014 shallowfbcspnet-raw Acc: 0.6366\n",
      "Source: bnci2014001 Target: weibo2014 shallowfbcspnet-cnorm Acc: 0.6248\n",
      "Source: bnci2014001 Target: weibo2014 shallowfbcspnet-tnorm Acc: 0.6326\n",
      "Source: bnci2014001 Target: weibo2014 shallowfbcspnet-euclid Acc: 0.7003\n",
      "Source: bnci2014001 Target: weibo2014 shallowfbcspnet-riemann Acc: 0.6923\n",
      "Source: bnci2014001 Target: cho2017 shallowfbcspnet-raw Acc: 0.5358\n",
      "Source: bnci2014001 Target: cho2017 shallowfbcspnet-cnorm Acc: 0.5768\n",
      "Source: bnci2014001 Target: cho2017 shallowfbcspnet-tnorm Acc: 0.5862\n",
      "Source: bnci2014001 Target: cho2017 shallowfbcspnet-euclid Acc: 0.5908\n",
      "Source: bnci2014001 Target: cho2017 shallowfbcspnet-riemann Acc: 0.5862\n",
      "Source: eegbci Target: bnci2014001 shallowfbcspnet-raw Acc: 0.7298\n",
      "Source: eegbci Target: bnci2014001 shallowfbcspnet-cnorm Acc: 0.6432\n",
      "Source: eegbci Target: bnci2014001 shallowfbcspnet-tnorm Acc: 0.6870\n",
      "Source: eegbci Target: bnci2014001 shallowfbcspnet-euclid Acc: 0.7343\n",
      "Source: eegbci Target: bnci2014001 shallowfbcspnet-riemann Acc: 0.7383\n",
      "Source: eegbci Target: eegbci shallowfbcspnet-raw Acc: 0.7155\n",
      "Source: eegbci Target: eegbci shallowfbcspnet-cnorm Acc: 0.6900\n",
      "Source: eegbci Target: eegbci shallowfbcspnet-tnorm Acc: 0.7007\n",
      "Source: eegbci Target: eegbci shallowfbcspnet-euclid Acc: 0.7063\n",
      "Source: eegbci Target: eegbci shallowfbcspnet-riemann Acc: 0.7099\n",
      "Source: eegbci Target: weibo2014 shallowfbcspnet-raw Acc: 0.6609\n",
      "Source: eegbci Target: weibo2014 shallowfbcspnet-cnorm Acc: 0.6094\n",
      "Source: eegbci Target: weibo2014 shallowfbcspnet-tnorm Acc: 0.6458\n",
      "Source: eegbci Target: weibo2014 shallowfbcspnet-euclid Acc: 0.7147\n",
      "Source: eegbci Target: weibo2014 shallowfbcspnet-riemann Acc: 0.7155\n",
      "Source: eegbci Target: cho2017 shallowfbcspnet-raw Acc: 0.6066\n",
      "Source: eegbci Target: cho2017 shallowfbcspnet-cnorm Acc: 0.5700\n",
      "Source: eegbci Target: cho2017 shallowfbcspnet-tnorm Acc: 0.5906\n",
      "Source: eegbci Target: cho2017 shallowfbcspnet-euclid Acc: 0.6189\n",
      "Source: eegbci Target: cho2017 shallowfbcspnet-riemann Acc: 0.6227\n",
      "Source: weibo2014 Target: bnci2014001 shallowfbcspnet-raw Acc: 0.6297\n",
      "Source: weibo2014 Target: bnci2014001 shallowfbcspnet-cnorm Acc: 0.6468\n",
      "Source: weibo2014 Target: bnci2014001 shallowfbcspnet-tnorm Acc: 0.6243\n",
      "Source: weibo2014 Target: bnci2014001 shallowfbcspnet-euclid Acc: 0.7108\n",
      "Source: weibo2014 Target: bnci2014001 shallowfbcspnet-riemann Acc: 0.7093\n",
      "Source: weibo2014 Target: eegbci shallowfbcspnet-raw Acc: 0.5916\n",
      "Source: weibo2014 Target: eegbci shallowfbcspnet-cnorm Acc: 0.5905\n",
      "Source: weibo2014 Target: eegbci shallowfbcspnet-tnorm Acc: 0.6019\n",
      "Source: weibo2014 Target: eegbci shallowfbcspnet-euclid Acc: 0.6339\n",
      "Source: weibo2014 Target: eegbci shallowfbcspnet-riemann Acc: 0.6324\n",
      "Source: weibo2014 Target: weibo2014 shallowfbcspnet-raw Acc: 0.7116\n",
      "Source: weibo2014 Target: weibo2014 shallowfbcspnet-cnorm Acc: 0.7036\n",
      "Source: weibo2014 Target: weibo2014 shallowfbcspnet-tnorm Acc: 0.7025\n",
      "Source: weibo2014 Target: weibo2014 shallowfbcspnet-euclid Acc: 0.7627\n",
      "Source: weibo2014 Target: weibo2014 shallowfbcspnet-riemann Acc: 0.7609\n",
      "Source: weibo2014 Target: cho2017 shallowfbcspnet-raw Acc: 0.5562\n",
      "Source: weibo2014 Target: cho2017 shallowfbcspnet-cnorm Acc: 0.5675\n",
      "Source: weibo2014 Target: cho2017 shallowfbcspnet-tnorm Acc: 0.5655\n",
      "Source: weibo2014 Target: cho2017 shallowfbcspnet-euclid Acc: 0.6314\n",
      "Source: weibo2014 Target: cho2017 shallowfbcspnet-riemann Acc: 0.6300\n",
      "Source: cho2017 Target: bnci2014001 shallowfbcspnet-raw Acc: 0.5092\n",
      "Source: cho2017 Target: bnci2014001 shallowfbcspnet-cnorm Acc: 0.6473\n",
      "Source: cho2017 Target: bnci2014001 shallowfbcspnet-tnorm Acc: 0.6407\n",
      "Source: cho2017 Target: bnci2014001 shallowfbcspnet-euclid Acc: 0.7183\n",
      "Source: cho2017 Target: bnci2014001 shallowfbcspnet-riemann Acc: 0.7211\n",
      "Source: cho2017 Target: eegbci shallowfbcspnet-raw Acc: 0.5597\n",
      "Source: cho2017 Target: eegbci shallowfbcspnet-cnorm Acc: 0.6045\n",
      "Source: cho2017 Target: eegbci shallowfbcspnet-tnorm Acc: 0.5985\n",
      "Source: cho2017 Target: eegbci shallowfbcspnet-euclid Acc: 0.6517\n",
      "Source: cho2017 Target: eegbci shallowfbcspnet-riemann Acc: 0.6527\n",
      "Source: cho2017 Target: weibo2014 shallowfbcspnet-raw Acc: 0.5238\n",
      "Source: cho2017 Target: weibo2014 shallowfbcspnet-cnorm Acc: 0.6664\n",
      "Source: cho2017 Target: weibo2014 shallowfbcspnet-tnorm Acc: 0.6461\n",
      "Source: cho2017 Target: weibo2014 shallowfbcspnet-euclid Acc: 0.7425\n",
      "Source: cho2017 Target: weibo2014 shallowfbcspnet-riemann Acc: 0.7378\n",
      "Source: cho2017 Target: cho2017 shallowfbcspnet-raw Acc: 0.7079\n",
      "Source: cho2017 Target: cho2017 shallowfbcspnet-cnorm Acc: 0.6864\n",
      "Source: cho2017 Target: cho2017 shallowfbcspnet-tnorm Acc: 0.6995\n",
      "Source: cho2017 Target: cho2017 shallowfbcspnet-euclid Acc: 0.7015\n",
      "Source: cho2017 Target: cho2017 shallowfbcspnet-riemann Acc: 0.7040\n",
      "Source: bnci2014001 Target: bnci2014001 eegnetv4-raw Acc: 0.8785\n",
      "Source: bnci2014001 Target: bnci2014001 eegnetv4-cnorm Acc: 0.8716\n",
      "Source: bnci2014001 Target: bnci2014001 eegnetv4-tnorm Acc: 0.8762\n",
      "Source: bnci2014001 Target: bnci2014001 eegnetv4-euclid Acc: 0.8933\n",
      "Source: bnci2014001 Target: bnci2014001 eegnetv4-riemann Acc: 0.8856\n",
      "Source: bnci2014001 Target: eegbci eegnetv4-raw Acc: 0.6248\n",
      "Source: bnci2014001 Target: eegbci eegnetv4-cnorm Acc: 0.6237\n",
      "Source: bnci2014001 Target: eegbci eegnetv4-tnorm Acc: 0.6250\n",
      "Source: bnci2014001 Target: eegbci eegnetv4-euclid Acc: 0.6471\n",
      "Source: bnci2014001 Target: eegbci eegnetv4-riemann Acc: 0.6450\n",
      "Source: bnci2014001 Target: weibo2014 eegnetv4-raw Acc: 0.6078\n",
      "Source: bnci2014001 Target: weibo2014 eegnetv4-cnorm Acc: 0.6122\n",
      "Source: bnci2014001 Target: weibo2014 eegnetv4-tnorm Acc: 0.6132\n",
      "Source: bnci2014001 Target: weibo2014 eegnetv4-euclid Acc: 0.6660\n",
      "Source: bnci2014001 Target: weibo2014 eegnetv4-riemann Acc: 0.6704\n",
      "Source: bnci2014001 Target: cho2017 eegnetv4-raw Acc: 0.5649\n",
      "Source: bnci2014001 Target: cho2017 eegnetv4-cnorm Acc: 0.5580\n",
      "Source: bnci2014001 Target: cho2017 eegnetv4-tnorm Acc: 0.5766\n",
      "Source: bnci2014001 Target: cho2017 eegnetv4-euclid Acc: 0.5836\n",
      "Source: bnci2014001 Target: cho2017 eegnetv4-riemann Acc: 0.5845\n",
      "Source: eegbci Target: bnci2014001 eegnetv4-raw Acc: 0.7461\n",
      "Source: eegbci Target: bnci2014001 eegnetv4-cnorm Acc: 0.7464\n",
      "Source: eegbci Target: bnci2014001 eegnetv4-tnorm Acc: 0.7390\n",
      "Source: eegbci Target: bnci2014001 eegnetv4-euclid Acc: 0.7846\n",
      "Source: eegbci Target: bnci2014001 eegnetv4-riemann Acc: 0.7799\n",
      "Source: eegbci Target: eegbci eegnetv4-raw Acc: 0.6848\n",
      "Source: eegbci Target: eegbci eegnetv4-cnorm Acc: 0.6871\n",
      "Source: eegbci Target: eegbci eegnetv4-tnorm Acc: 0.6884\n",
      "Source: eegbci Target: eegbci eegnetv4-euclid Acc: 0.7210\n",
      "Source: eegbci Target: eegbci eegnetv4-riemann Acc: 0.7130\n",
      "Source: eegbci Target: weibo2014 eegnetv4-raw Acc: 0.6349\n",
      "Source: eegbci Target: weibo2014 eegnetv4-cnorm Acc: 0.6541\n",
      "Source: eegbci Target: weibo2014 eegnetv4-tnorm Acc: 0.6621\n",
      "Source: eegbci Target: weibo2014 eegnetv4-euclid Acc: 0.7045\n",
      "Source: eegbci Target: weibo2014 eegnetv4-riemann Acc: 0.7042\n",
      "Source: eegbci Target: cho2017 eegnetv4-raw Acc: 0.5890\n",
      "Source: eegbci Target: cho2017 eegnetv4-cnorm Acc: 0.5771\n",
      "Source: eegbci Target: cho2017 eegnetv4-tnorm Acc: 0.5971\n",
      "Source: eegbci Target: cho2017 eegnetv4-euclid Acc: 0.6286\n",
      "Source: eegbci Target: cho2017 eegnetv4-riemann Acc: 0.6242\n",
      "Source: weibo2014 Target: bnci2014001 eegnetv4-raw Acc: 0.6573\n",
      "Source: weibo2014 Target: bnci2014001 eegnetv4-cnorm Acc: 0.6498\n",
      "Source: weibo2014 Target: bnci2014001 eegnetv4-tnorm Acc: 0.6657\n",
      "Source: weibo2014 Target: bnci2014001 eegnetv4-euclid Acc: 0.7041\n",
      "Source: weibo2014 Target: bnci2014001 eegnetv4-riemann Acc: 0.6838\n",
      "Source: weibo2014 Target: eegbci eegnetv4-raw Acc: 0.5962\n",
      "Source: weibo2014 Target: eegbci eegnetv4-cnorm Acc: 0.5977\n",
      "Source: weibo2014 Target: eegbci eegnetv4-tnorm Acc: 0.6040\n",
      "Source: weibo2014 Target: eegbci eegnetv4-euclid Acc: 0.6373\n",
      "Source: weibo2014 Target: eegbci eegnetv4-riemann Acc: 0.6358\n",
      "Source: weibo2014 Target: weibo2014 eegnetv4-raw Acc: 0.7217\n",
      "Source: weibo2014 Target: weibo2014 eegnetv4-cnorm Acc: 0.7307\n",
      "Source: weibo2014 Target: weibo2014 eegnetv4-tnorm Acc: 0.7326\n",
      "Source: weibo2014 Target: weibo2014 eegnetv4-euclid Acc: 0.7602\n",
      "Source: weibo2014 Target: weibo2014 eegnetv4-riemann Acc: 0.7696\n",
      "Source: weibo2014 Target: cho2017 eegnetv4-raw Acc: 0.5646\n",
      "Source: weibo2014 Target: cho2017 eegnetv4-cnorm Acc: 0.5780\n",
      "Source: weibo2014 Target: cho2017 eegnetv4-tnorm Acc: 0.6020\n",
      "Source: weibo2014 Target: cho2017 eegnetv4-euclid Acc: 0.6371\n",
      "Source: weibo2014 Target: cho2017 eegnetv4-riemann Acc: 0.6315\n",
      "Source: cho2017 Target: bnci2014001 eegnetv4-raw Acc: 0.5000\n",
      "Source: cho2017 Target: bnci2014001 eegnetv4-cnorm Acc: 0.6706\n",
      "Source: cho2017 Target: bnci2014001 eegnetv4-tnorm Acc: 0.6632\n",
      "Source: cho2017 Target: bnci2014001 eegnetv4-euclid Acc: 0.7020\n",
      "Source: cho2017 Target: bnci2014001 eegnetv4-riemann Acc: 0.7034\n",
      "Source: cho2017 Target: eegbci eegnetv4-raw Acc: 0.5109\n",
      "Source: cho2017 Target: eegbci eegnetv4-cnorm Acc: 0.6049\n",
      "Source: cho2017 Target: eegbci eegnetv4-tnorm Acc: 0.6132\n",
      "Source: cho2017 Target: eegbci eegnetv4-euclid Acc: 0.6647\n",
      "Source: cho2017 Target: eegbci eegnetv4-riemann Acc: 0.6624\n",
      "Source: cho2017 Target: weibo2014 eegnetv4-raw Acc: 0.5000\n",
      "Source: cho2017 Target: weibo2014 eegnetv4-cnorm Acc: 0.6503\n",
      "Source: cho2017 Target: weibo2014 eegnetv4-tnorm Acc: 0.6666\n",
      "Source: cho2017 Target: weibo2014 eegnetv4-euclid Acc: 0.7327\n",
      "Source: cho2017 Target: weibo2014 eegnetv4-riemann Acc: 0.7224\n",
      "Source: cho2017 Target: cho2017 eegnetv4-raw Acc: 0.7195\n",
      "Source: cho2017 Target: cho2017 eegnetv4-cnorm Acc: 0.7075\n",
      "Source: cho2017 Target: cho2017 eegnetv4-tnorm Acc: 0.7167\n",
      "Source: cho2017 Target: cho2017 eegnetv4-euclid Acc: 0.7339\n",
      "Source: cho2017 Target: cho2017 eegnetv4-riemann Acc: 0.7306\n",
      "Source: bnci2014001 Target: bnci2014001 tidnet-raw Acc: 0.6131\n",
      "Source: bnci2014001 Target: bnci2014001 tidnet-cnorm Acc: 0.5657\n",
      "Source: bnci2014001 Target: bnci2014001 tidnet-tnorm Acc: 0.6107\n",
      "Source: bnci2014001 Target: bnci2014001 tidnet-euclid Acc: 0.7872\n",
      "Source: bnci2014001 Target: bnci2014001 tidnet-riemann Acc: 0.8007\n",
      "Source: bnci2014001 Target: eegbci tidnet-raw Acc: 0.5295\n",
      "Source: bnci2014001 Target: eegbci tidnet-cnorm Acc: 0.5172\n",
      "Source: bnci2014001 Target: eegbci tidnet-tnorm Acc: 0.5341\n",
      "Source: bnci2014001 Target: eegbci tidnet-euclid Acc: 0.6376\n",
      "Source: bnci2014001 Target: eegbci tidnet-riemann Acc: 0.6446\n",
      "Source: bnci2014001 Target: weibo2014 tidnet-raw Acc: 0.5696\n",
      "Source: bnci2014001 Target: weibo2014 tidnet-cnorm Acc: 0.5227\n",
      "Source: bnci2014001 Target: weibo2014 tidnet-tnorm Acc: 0.5628\n",
      "Source: bnci2014001 Target: weibo2014 tidnet-euclid Acc: 0.6586\n",
      "Source: bnci2014001 Target: weibo2014 tidnet-riemann Acc: 0.6582\n",
      "Source: bnci2014001 Target: cho2017 tidnet-raw Acc: 0.5068\n",
      "Source: bnci2014001 Target: cho2017 tidnet-cnorm Acc: 0.4936\n",
      "Source: bnci2014001 Target: cho2017 tidnet-tnorm Acc: 0.5156\n",
      "Source: bnci2014001 Target: cho2017 tidnet-euclid Acc: 0.5514\n",
      "Source: bnci2014001 Target: cho2017 tidnet-riemann Acc: 0.5557\n",
      "Source: eegbci Target: bnci2014001 tidnet-raw Acc: 0.5334\n",
      "Source: eegbci Target: bnci2014001 tidnet-cnorm Acc: 0.5245\n",
      "Source: eegbci Target: bnci2014001 tidnet-tnorm Acc: 0.5530\n",
      "Source: eegbci Target: bnci2014001 tidnet-euclid Acc: 0.6951\n",
      "Source: eegbci Target: bnci2014001 tidnet-riemann Acc: 0.6973\n",
      "Source: eegbci Target: eegbci tidnet-raw Acc: 0.5489\n",
      "Source: eegbci Target: eegbci tidnet-cnorm Acc: 0.5313\n",
      "Source: eegbci Target: eegbci tidnet-tnorm Acc: 0.5640\n",
      "Source: eegbci Target: eegbci tidnet-euclid Acc: 0.6277\n",
      "Source: eegbci Target: eegbci tidnet-riemann Acc: 0.6365\n",
      "Source: eegbci Target: weibo2014 tidnet-raw Acc: 0.5312\n",
      "Source: eegbci Target: weibo2014 tidnet-cnorm Acc: 0.5230\n",
      "Source: eegbci Target: weibo2014 tidnet-tnorm Acc: 0.5535\n",
      "Source: eegbci Target: weibo2014 tidnet-euclid Acc: 0.6186\n",
      "Source: eegbci Target: weibo2014 tidnet-riemann Acc: 0.6382\n",
      "Source: eegbci Target: cho2017 tidnet-raw Acc: 0.5093\n",
      "Source: eegbci Target: cho2017 tidnet-cnorm Acc: 0.5068\n",
      "Source: eegbci Target: cho2017 tidnet-tnorm Acc: 0.5166\n",
      "Source: eegbci Target: cho2017 tidnet-euclid Acc: 0.5569\n",
      "Source: eegbci Target: cho2017 tidnet-riemann Acc: 0.5579\n",
      "Source: weibo2014 Target: bnci2014001 tidnet-raw Acc: 0.5522\n",
      "Source: weibo2014 Target: bnci2014001 tidnet-cnorm Acc: 0.5143\n",
      "Source: weibo2014 Target: bnci2014001 tidnet-tnorm Acc: 0.5549\n",
      "Source: weibo2014 Target: bnci2014001 tidnet-euclid Acc: 0.6519\n",
      "Source: weibo2014 Target: bnci2014001 tidnet-riemann Acc: 0.6552\n",
      "Source: weibo2014 Target: eegbci tidnet-raw Acc: 0.5468\n",
      "Source: weibo2014 Target: eegbci tidnet-cnorm Acc: 0.5084\n",
      "Source: weibo2014 Target: eegbci tidnet-tnorm Acc: 0.5476\n",
      "Source: weibo2014 Target: eegbci tidnet-euclid Acc: 0.5953\n",
      "Source: weibo2014 Target: eegbci tidnet-riemann Acc: 0.5903\n",
      "Source: weibo2014 Target: weibo2014 tidnet-raw Acc: 0.6299\n",
      "Source: weibo2014 Target: weibo2014 tidnet-cnorm Acc: 0.5525\n",
      "Source: weibo2014 Target: weibo2014 tidnet-tnorm Acc: 0.6133\n",
      "Source: weibo2014 Target: weibo2014 tidnet-euclid Acc: 0.7008\n",
      "Source: weibo2014 Target: weibo2014 tidnet-riemann Acc: 0.7059\n",
      "Source: weibo2014 Target: cho2017 tidnet-raw Acc: 0.5162\n",
      "Source: weibo2014 Target: cho2017 tidnet-cnorm Acc: 0.5011\n",
      "Source: weibo2014 Target: cho2017 tidnet-tnorm Acc: 0.5207\n",
      "Source: weibo2014 Target: cho2017 tidnet-euclid Acc: 0.5753\n",
      "Source: weibo2014 Target: cho2017 tidnet-riemann Acc: 0.5790\n",
      "Source: cho2017 Target: bnci2014001 tidnet-raw Acc: 0.4998\n",
      "Source: cho2017 Target: bnci2014001 tidnet-cnorm Acc: 0.4906\n",
      "Source: cho2017 Target: bnci2014001 tidnet-tnorm Acc: 0.4978\n",
      "Source: cho2017 Target: bnci2014001 tidnet-euclid Acc: 0.6473\n",
      "Source: cho2017 Target: bnci2014001 tidnet-riemann Acc: 0.6529\n",
      "Source: cho2017 Target: eegbci tidnet-raw Acc: 0.5027\n",
      "Source: cho2017 Target: eegbci tidnet-cnorm Acc: 0.5041\n",
      "Source: cho2017 Target: eegbci tidnet-tnorm Acc: 0.5130\n",
      "Source: cho2017 Target: eegbci tidnet-euclid Acc: 0.6035\n",
      "Source: cho2017 Target: eegbci tidnet-riemann Acc: 0.5992\n",
      "Source: cho2017 Target: weibo2014 tidnet-raw Acc: 0.5022\n",
      "Source: cho2017 Target: weibo2014 tidnet-cnorm Acc: 0.5027\n",
      "Source: cho2017 Target: weibo2014 tidnet-tnorm Acc: 0.5210\n",
      "Source: cho2017 Target: weibo2014 tidnet-euclid Acc: 0.6745\n",
      "Source: cho2017 Target: weibo2014 tidnet-riemann Acc: 0.6706\n",
      "Source: cho2017 Target: cho2017 tidnet-raw Acc: 0.5444\n",
      "Source: cho2017 Target: cho2017 tidnet-cnorm Acc: 0.5354\n",
      "Source: cho2017 Target: cho2017 tidnet-tnorm Acc: 0.5450\n",
      "Source: cho2017 Target: cho2017 tidnet-euclid Acc: 0.6340\n",
      "Source: cho2017 Target: cho2017 tidnet-riemann Acc: 0.6295\n"
     ]
    }
   ],
   "source": [
    "srate = 128\n",
    "datasets = [BNCI2014001(), PhysionetMI(), Weibo2014(), Cho2017()]\n",
    "selected_channels = ['FZ', 'FC3', 'FC1', 'FCZ', 'FC2', 'FC4', 'C5', 'C3', 'C1', 'CZ', 'C2', 'C4', 'C6', 'CP3', 'CP1', 'CPZ', 'CP2', 'CP4', 'P1', 'PZ', 'P2', 'POZ']\n",
    "duration = 3 # seconds\n",
    "events = ['left_hand', 'right_hand']\n",
    "preprocess_methods = ['raw', 'cnorm', 'tnorm', 'euclid', 'riemann']\n",
    "kfold = 5\n",
    "\n",
    "model_names = ['shallownet', 'eegnet', 'shallowfbcspnet', 'eegnetv4', 'tidnet']\n",
    "for model_name in model_names:\n",
    "    for source_dataset in datasets:\n",
    "        for target_dataset in datasets:\n",
    "            cross_dataset_network_predict(\n",
    "                model_name, source_dataset, target_dataset, selected_channels, srate, duration, events,\n",
    "                kfold=kfold, \n",
    "                save_folder=model_name,\n",
    "                preprocess_methods=preprocess_methods,\n",
    "                use_adabn=False,\n",
    "                force_update=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: bnci2014001 Target: bnci2014001 shallownet-raw-adabn Acc: 0.8232\n",
      "Source: bnci2014001 Target: bnci2014001 shallownet-cnorm-adabn Acc: 0.8197\n",
      "Source: bnci2014001 Target: bnci2014001 shallownet-tnorm-adabn Acc: 0.8047\n",
      "Source: bnci2014001 Target: bnci2014001 shallownet-euclid-adabn Acc: 0.8645\n",
      "Source: bnci2014001 Target: bnci2014001 shallownet-riemann-adabn Acc: 0.8637\n",
      "Source: bnci2014001 Target: eegbci shallownet-raw-adabn Acc: 0.6374\n",
      "Source: bnci2014001 Target: eegbci shallownet-cnorm-adabn Acc: 0.6251\n",
      "Source: bnci2014001 Target: eegbci shallownet-tnorm-adabn Acc: 0.6394\n",
      "Source: bnci2014001 Target: eegbci shallownet-euclid-adabn Acc: 0.6579\n",
      "Source: bnci2014001 Target: eegbci shallownet-riemann-adabn Acc: 0.6481\n",
      "Source: bnci2014001 Target: weibo2014 shallownet-raw-adabn Acc: 0.6419\n",
      "Source: bnci2014001 Target: weibo2014 shallownet-cnorm-adabn Acc: 0.6514\n",
      "Source: bnci2014001 Target: weibo2014 shallownet-tnorm-adabn Acc: 0.6542\n",
      "Source: bnci2014001 Target: weibo2014 shallownet-euclid-adabn Acc: 0.7158\n",
      "Source: bnci2014001 Target: weibo2014 shallownet-riemann-adabn Acc: 0.7133\n",
      "Source: bnci2014001 Target: cho2017 shallownet-raw-adabn Acc: 0.5981\n",
      "Source: bnci2014001 Target: cho2017 shallownet-cnorm-adabn Acc: 0.5909\n",
      "Source: bnci2014001 Target: cho2017 shallownet-tnorm-adabn Acc: 0.6049\n",
      "Source: bnci2014001 Target: cho2017 shallownet-euclid-adabn Acc: 0.5965\n",
      "Source: bnci2014001 Target: cho2017 shallownet-riemann-adabn Acc: 0.5927\n",
      "Source: eegbci Target: bnci2014001 shallownet-raw-adabn Acc: 0.7557\n",
      "Source: eegbci Target: bnci2014001 shallownet-cnorm-adabn Acc: 0.7067\n",
      "Source: eegbci Target: bnci2014001 shallownet-tnorm-adabn Acc: 0.7225\n",
      "Source: eegbci Target: bnci2014001 shallownet-euclid-adabn Acc: 0.7383\n",
      "Source: eegbci Target: bnci2014001 shallownet-riemann-adabn Acc: 0.7449\n",
      "Source: eegbci Target: eegbci shallownet-raw-adabn Acc: 0.7218\n",
      "Source: eegbci Target: eegbci shallownet-cnorm-adabn Acc: 0.7062\n",
      "Source: eegbci Target: eegbci shallownet-tnorm-adabn Acc: 0.7049\n",
      "Source: eegbci Target: eegbci shallownet-euclid-adabn Acc: 0.6938\n",
      "Source: eegbci Target: eegbci shallownet-riemann-adabn Acc: 0.6963\n",
      "Source: eegbci Target: weibo2014 shallownet-raw-adabn Acc: 0.6963\n",
      "Source: eegbci Target: weibo2014 shallownet-cnorm-adabn Acc: 0.6617\n",
      "Source: eegbci Target: weibo2014 shallownet-tnorm-adabn Acc: 0.6741\n",
      "Source: eegbci Target: weibo2014 shallownet-euclid-adabn Acc: 0.7092\n",
      "Source: eegbci Target: weibo2014 shallownet-riemann-adabn Acc: 0.7163\n",
      "Source: eegbci Target: cho2017 shallownet-raw-adabn Acc: 0.6220\n",
      "Source: eegbci Target: cho2017 shallownet-cnorm-adabn Acc: 0.5822\n",
      "Source: eegbci Target: cho2017 shallownet-tnorm-adabn Acc: 0.6061\n",
      "Source: eegbci Target: cho2017 shallownet-euclid-adabn Acc: 0.6134\n",
      "Source: eegbci Target: cho2017 shallownet-riemann-adabn Acc: 0.6144\n",
      "Source: weibo2014 Target: bnci2014001 shallownet-raw-adabn Acc: 0.6577\n",
      "Source: weibo2014 Target: bnci2014001 shallownet-cnorm-adabn Acc: 0.6406\n",
      "Source: weibo2014 Target: bnci2014001 shallownet-tnorm-adabn Acc: 0.6435\n",
      "Source: weibo2014 Target: bnci2014001 shallownet-euclid-adabn Acc: 0.6892\n",
      "Source: weibo2014 Target: bnci2014001 shallownet-riemann-adabn Acc: 0.6871\n",
      "Source: weibo2014 Target: eegbci shallownet-raw-adabn Acc: 0.6231\n",
      "Source: weibo2014 Target: eegbci shallownet-cnorm-adabn Acc: 0.5846\n",
      "Source: weibo2014 Target: eegbci shallownet-tnorm-adabn Acc: 0.6157\n",
      "Source: weibo2014 Target: eegbci shallownet-euclid-adabn Acc: 0.6259\n",
      "Source: weibo2014 Target: eegbci shallownet-riemann-adabn Acc: 0.6238\n",
      "Source: weibo2014 Target: weibo2014 shallownet-raw-adabn Acc: 0.7339\n",
      "Source: weibo2014 Target: weibo2014 shallownet-cnorm-adabn Acc: 0.6984\n",
      "Source: weibo2014 Target: weibo2014 shallownet-tnorm-adabn Acc: 0.6949\n",
      "Source: weibo2014 Target: weibo2014 shallownet-euclid-adabn Acc: 0.7727\n",
      "Source: weibo2014 Target: weibo2014 shallownet-riemann-adabn Acc: 0.7770\n",
      "Source: weibo2014 Target: cho2017 shallownet-raw-adabn Acc: 0.5898\n",
      "Source: weibo2014 Target: cho2017 shallownet-cnorm-adabn Acc: 0.5785\n",
      "Source: weibo2014 Target: cho2017 shallownet-tnorm-adabn Acc: 0.5877\n",
      "Source: weibo2014 Target: cho2017 shallownet-euclid-adabn Acc: 0.6234\n",
      "Source: weibo2014 Target: cho2017 shallownet-riemann-adabn Acc: 0.6198\n",
      "Source: cho2017 Target: bnci2014001 shallownet-raw-adabn Acc: 0.6465\n",
      "Source: cho2017 Target: bnci2014001 shallownet-cnorm-adabn Acc: 0.6536\n",
      "Source: cho2017 Target: bnci2014001 shallownet-tnorm-adabn Acc: 0.6475\n",
      "Source: cho2017 Target: bnci2014001 shallownet-euclid-adabn Acc: 0.7051\n",
      "Source: cho2017 Target: bnci2014001 shallownet-riemann-adabn Acc: 0.7091\n",
      "Source: cho2017 Target: eegbci shallownet-raw-adabn Acc: 0.6193\n",
      "Source: cho2017 Target: eegbci shallownet-cnorm-adabn Acc: 0.6099\n",
      "Source: cho2017 Target: eegbci shallownet-tnorm-adabn Acc: 0.6144\n",
      "Source: cho2017 Target: eegbci shallownet-euclid-adabn Acc: 0.6529\n",
      "Source: cho2017 Target: eegbci shallownet-riemann-adabn Acc: 0.6525\n",
      "Source: cho2017 Target: weibo2014 shallownet-raw-adabn Acc: 0.6640\n",
      "Source: cho2017 Target: weibo2014 shallownet-cnorm-adabn Acc: 0.6863\n",
      "Source: cho2017 Target: weibo2014 shallownet-tnorm-adabn Acc: 0.6752\n",
      "Source: cho2017 Target: weibo2014 shallownet-euclid-adabn Acc: 0.7384\n",
      "Source: cho2017 Target: weibo2014 shallownet-riemann-adabn Acc: 0.7366\n",
      "Source: cho2017 Target: cho2017 shallownet-raw-adabn Acc: 0.7034\n",
      "Source: cho2017 Target: cho2017 shallownet-cnorm-adabn Acc: 0.6829\n",
      "Source: cho2017 Target: cho2017 shallownet-tnorm-adabn Acc: 0.6986\n",
      "Source: cho2017 Target: cho2017 shallownet-euclid-adabn Acc: 0.7030\n",
      "Source: cho2017 Target: cho2017 shallownet-riemann-adabn Acc: 0.6983\n",
      "Source: bnci2014001 Target: bnci2014001 eegnet-raw-adabn Acc: 0.8191\n",
      "Source: bnci2014001 Target: bnci2014001 eegnet-cnorm-adabn Acc: 0.8170\n",
      "Source: bnci2014001 Target: bnci2014001 eegnet-tnorm-adabn Acc: 0.8221\n",
      "Source: bnci2014001 Target: bnci2014001 eegnet-euclid-adabn Acc: 0.8855\n",
      "Source: bnci2014001 Target: bnci2014001 eegnet-riemann-adabn Acc: 0.8874\n",
      "Source: bnci2014001 Target: eegbci eegnet-raw-adabn Acc: 0.6387\n",
      "Source: bnci2014001 Target: eegbci eegnet-cnorm-adabn Acc: 0.6266\n",
      "Source: bnci2014001 Target: eegbci eegnet-tnorm-adabn Acc: 0.6394\n",
      "Source: bnci2014001 Target: eegbci eegnet-euclid-adabn Acc: 0.6675\n",
      "Source: bnci2014001 Target: eegbci eegnet-riemann-adabn Acc: 0.6714\n",
      "Source: bnci2014001 Target: weibo2014 eegnet-raw-adabn Acc: 0.6501\n",
      "Source: bnci2014001 Target: weibo2014 eegnet-cnorm-adabn Acc: 0.6381\n",
      "Source: bnci2014001 Target: weibo2014 eegnet-tnorm-adabn Acc: 0.6513\n",
      "Source: bnci2014001 Target: weibo2014 eegnet-euclid-adabn Acc: 0.6998\n",
      "Source: bnci2014001 Target: weibo2014 eegnet-riemann-adabn Acc: 0.6966\n",
      "Source: bnci2014001 Target: cho2017 eegnet-raw-adabn Acc: 0.6023\n",
      "Source: bnci2014001 Target: cho2017 eegnet-cnorm-adabn Acc: 0.5827\n",
      "Source: bnci2014001 Target: cho2017 eegnet-tnorm-adabn Acc: 0.6014\n",
      "Source: bnci2014001 Target: cho2017 eegnet-euclid-adabn Acc: 0.6071\n",
      "Source: bnci2014001 Target: cho2017 eegnet-riemann-adabn Acc: 0.6069\n",
      "Source: eegbci Target: bnci2014001 eegnet-raw-adabn Acc: 0.7022\n",
      "Source: eegbci Target: bnci2014001 eegnet-cnorm-adabn Acc: 0.7172\n",
      "Source: eegbci Target: bnci2014001 eegnet-tnorm-adabn Acc: 0.7367\n",
      "Source: eegbci Target: bnci2014001 eegnet-euclid-adabn Acc: 0.7782\n",
      "Source: eegbci Target: bnci2014001 eegnet-riemann-adabn Acc: 0.7749\n",
      "Source: eegbci Target: eegbci eegnet-raw-adabn Acc: 0.6574\n",
      "Source: eegbci Target: eegbci eegnet-cnorm-adabn Acc: 0.6652\n",
      "Source: eegbci Target: eegbci eegnet-tnorm-adabn Acc: 0.6788\n",
      "Source: eegbci Target: eegbci eegnet-euclid-adabn Acc: 0.7244\n",
      "Source: eegbci Target: eegbci eegnet-riemann-adabn Acc: 0.7185\n",
      "Source: eegbci Target: weibo2014 eegnet-raw-adabn Acc: 0.6166\n",
      "Source: eegbci Target: weibo2014 eegnet-cnorm-adabn Acc: 0.6347\n",
      "Source: eegbci Target: weibo2014 eegnet-tnorm-adabn Acc: 0.6632\n",
      "Source: eegbci Target: weibo2014 eegnet-euclid-adabn Acc: 0.7075\n",
      "Source: eegbci Target: weibo2014 eegnet-riemann-adabn Acc: 0.7231\n",
      "Source: eegbci Target: cho2017 eegnet-raw-adabn Acc: 0.5742\n",
      "Source: eegbci Target: cho2017 eegnet-cnorm-adabn Acc: 0.5832\n",
      "Source: eegbci Target: cho2017 eegnet-tnorm-adabn Acc: 0.5985\n",
      "Source: eegbci Target: cho2017 eegnet-euclid-adabn Acc: 0.6345\n",
      "Source: eegbci Target: cho2017 eegnet-riemann-adabn Acc: 0.6352\n",
      "Source: weibo2014 Target: bnci2014001 eegnet-raw-adabn Acc: 0.6675\n",
      "Source: weibo2014 Target: bnci2014001 eegnet-cnorm-adabn Acc: 0.6508\n",
      "Source: weibo2014 Target: bnci2014001 eegnet-tnorm-adabn Acc: 0.6536\n",
      "Source: weibo2014 Target: bnci2014001 eegnet-euclid-adabn Acc: 0.6965\n",
      "Source: weibo2014 Target: bnci2014001 eegnet-riemann-adabn Acc: 0.6950\n",
      "Source: weibo2014 Target: eegbci eegnet-raw-adabn Acc: 0.6218\n",
      "Source: weibo2014 Target: eegbci eegnet-cnorm-adabn Acc: 0.6083\n",
      "Source: weibo2014 Target: eegbci eegnet-tnorm-adabn Acc: 0.6229\n",
      "Source: weibo2014 Target: eegbci eegnet-euclid-adabn Acc: 0.6422\n",
      "Source: weibo2014 Target: eegbci eegnet-riemann-adabn Acc: 0.6410\n",
      "Source: weibo2014 Target: weibo2014 eegnet-raw-adabn Acc: 0.7159\n",
      "Source: weibo2014 Target: weibo2014 eegnet-cnorm-adabn Acc: 0.7059\n",
      "Source: weibo2014 Target: weibo2014 eegnet-tnorm-adabn Acc: 0.7123\n",
      "Source: weibo2014 Target: weibo2014 eegnet-euclid-adabn Acc: 0.7745\n",
      "Source: weibo2014 Target: weibo2014 eegnet-riemann-adabn Acc: 0.7818\n",
      "Source: weibo2014 Target: cho2017 eegnet-raw-adabn Acc: 0.5990\n",
      "Source: weibo2014 Target: cho2017 eegnet-cnorm-adabn Acc: 0.5837\n",
      "Source: weibo2014 Target: cho2017 eegnet-tnorm-adabn Acc: 0.5951\n",
      "Source: weibo2014 Target: cho2017 eegnet-euclid-adabn Acc: 0.6346\n",
      "Source: weibo2014 Target: cho2017 eegnet-riemann-adabn Acc: 0.6357\n",
      "Source: cho2017 Target: bnci2014001 eegnet-raw-adabn Acc: 0.6679\n",
      "Source: cho2017 Target: bnci2014001 eegnet-cnorm-adabn Acc: 0.6698\n",
      "Source: cho2017 Target: bnci2014001 eegnet-tnorm-adabn Acc: 0.6724\n",
      "Source: cho2017 Target: bnci2014001 eegnet-euclid-adabn Acc: 0.6924\n",
      "Source: cho2017 Target: bnci2014001 eegnet-riemann-adabn Acc: 0.6917\n",
      "Source: cho2017 Target: eegbci eegnet-raw-adabn Acc: 0.6189\n",
      "Source: cho2017 Target: eegbci eegnet-cnorm-adabn Acc: 0.6165\n",
      "Source: cho2017 Target: eegbci eegnet-tnorm-adabn Acc: 0.6253\n",
      "Source: cho2017 Target: eegbci eegnet-euclid-adabn Acc: 0.6607\n",
      "Source: cho2017 Target: eegbci eegnet-riemann-adabn Acc: 0.6583\n",
      "Source: cho2017 Target: weibo2014 eegnet-raw-adabn Acc: 0.6490\n",
      "Source: cho2017 Target: weibo2014 eegnet-cnorm-adabn Acc: 0.6562\n",
      "Source: cho2017 Target: weibo2014 eegnet-tnorm-adabn Acc: 0.6644\n",
      "Source: cho2017 Target: weibo2014 eegnet-euclid-adabn Acc: 0.7265\n",
      "Source: cho2017 Target: weibo2014 eegnet-riemann-adabn Acc: 0.7295\n",
      "Source: cho2017 Target: cho2017 eegnet-raw-adabn Acc: 0.6911\n",
      "Source: cho2017 Target: cho2017 eegnet-cnorm-adabn Acc: 0.6920\n",
      "Source: cho2017 Target: cho2017 eegnet-tnorm-adabn Acc: 0.6916\n",
      "Source: cho2017 Target: cho2017 eegnet-euclid-adabn Acc: 0.7202\n",
      "Source: cho2017 Target: cho2017 eegnet-riemann-adabn Acc: 0.7183\n",
      "Source: bnci2014001 Target: bnci2014001 shallowfbcspnet-raw-adabn Acc: 0.8214\n",
      "Source: bnci2014001 Target: bnci2014001 shallowfbcspnet-cnorm-adabn Acc: 0.8015\n",
      "Source: bnci2014001 Target: bnci2014001 shallowfbcspnet-tnorm-adabn Acc: 0.8074\n",
      "Source: bnci2014001 Target: bnci2014001 shallowfbcspnet-euclid-adabn Acc: 0.8305\n",
      "Source: bnci2014001 Target: bnci2014001 shallowfbcspnet-riemann-adabn Acc: 0.8313\n",
      "Source: bnci2014001 Target: eegbci shallowfbcspnet-raw-adabn Acc: 0.6395\n",
      "Source: bnci2014001 Target: eegbci shallowfbcspnet-cnorm-adabn Acc: 0.6223\n",
      "Source: bnci2014001 Target: eegbci shallowfbcspnet-tnorm-adabn Acc: 0.6308\n",
      "Source: bnci2014001 Target: eegbci shallowfbcspnet-euclid-adabn Acc: 0.6530\n",
      "Source: bnci2014001 Target: eegbci shallowfbcspnet-riemann-adabn Acc: 0.6488\n",
      "Source: bnci2014001 Target: weibo2014 shallowfbcspnet-raw-adabn Acc: 0.6569\n",
      "Source: bnci2014001 Target: weibo2014 shallowfbcspnet-cnorm-adabn Acc: 0.6607\n",
      "Source: bnci2014001 Target: weibo2014 shallowfbcspnet-tnorm-adabn Acc: 0.6670\n",
      "Source: bnci2014001 Target: weibo2014 shallowfbcspnet-euclid-adabn Acc: 0.7213\n",
      "Source: bnci2014001 Target: weibo2014 shallowfbcspnet-riemann-adabn Acc: 0.7206\n",
      "Source: bnci2014001 Target: cho2017 shallowfbcspnet-raw-adabn Acc: 0.5996\n",
      "Source: bnci2014001 Target: cho2017 shallowfbcspnet-cnorm-adabn Acc: 0.5939\n",
      "Source: bnci2014001 Target: cho2017 shallowfbcspnet-tnorm-adabn Acc: 0.6012\n",
      "Source: bnci2014001 Target: cho2017 shallowfbcspnet-euclid-adabn Acc: 0.6057\n",
      "Source: bnci2014001 Target: cho2017 shallowfbcspnet-riemann-adabn Acc: 0.6031\n",
      "Source: eegbci Target: bnci2014001 shallowfbcspnet-raw-adabn Acc: 0.7525\n",
      "Source: eegbci Target: bnci2014001 shallowfbcspnet-cnorm-adabn Acc: 0.6946\n",
      "Source: eegbci Target: bnci2014001 shallowfbcspnet-tnorm-adabn Acc: 0.7159\n",
      "Source: eegbci Target: bnci2014001 shallowfbcspnet-euclid-adabn Acc: 0.7373\n",
      "Source: eegbci Target: bnci2014001 shallowfbcspnet-riemann-adabn Acc: 0.7411\n",
      "Source: eegbci Target: eegbci shallowfbcspnet-raw-adabn Acc: 0.7195\n",
      "Source: eegbci Target: eegbci shallowfbcspnet-cnorm-adabn Acc: 0.6986\n",
      "Source: eegbci Target: eegbci shallowfbcspnet-tnorm-adabn Acc: 0.7128\n",
      "Source: eegbci Target: eegbci shallowfbcspnet-euclid-adabn Acc: 0.7093\n",
      "Source: eegbci Target: eegbci shallowfbcspnet-riemann-adabn Acc: 0.7135\n",
      "Source: eegbci Target: weibo2014 shallowfbcspnet-raw-adabn Acc: 0.6888\n",
      "Source: eegbci Target: weibo2014 shallowfbcspnet-cnorm-adabn Acc: 0.6629\n",
      "Source: eegbci Target: weibo2014 shallowfbcspnet-tnorm-adabn Acc: 0.6686\n",
      "Source: eegbci Target: weibo2014 shallowfbcspnet-euclid-adabn Acc: 0.7320\n",
      "Source: eegbci Target: weibo2014 shallowfbcspnet-riemann-adabn Acc: 0.7317\n",
      "Source: eegbci Target: cho2017 shallowfbcspnet-raw-adabn Acc: 0.6201\n",
      "Source: eegbci Target: cho2017 shallowfbcspnet-cnorm-adabn Acc: 0.5886\n",
      "Source: eegbci Target: cho2017 shallowfbcspnet-tnorm-adabn Acc: 0.6072\n",
      "Source: eegbci Target: cho2017 shallowfbcspnet-euclid-adabn Acc: 0.6221\n",
      "Source: eegbci Target: cho2017 shallowfbcspnet-riemann-adabn Acc: 0.6235\n",
      "Source: weibo2014 Target: bnci2014001 shallowfbcspnet-raw-adabn Acc: 0.6608\n",
      "Source: weibo2014 Target: bnci2014001 shallowfbcspnet-cnorm-adabn Acc: 0.6580\n",
      "Source: weibo2014 Target: bnci2014001 shallowfbcspnet-tnorm-adabn Acc: 0.6544\n",
      "Source: weibo2014 Target: bnci2014001 shallowfbcspnet-euclid-adabn Acc: 0.7116\n",
      "Source: weibo2014 Target: bnci2014001 shallowfbcspnet-riemann-adabn Acc: 0.7100\n",
      "Source: weibo2014 Target: eegbci shallowfbcspnet-raw-adabn Acc: 0.6188\n",
      "Source: weibo2014 Target: eegbci shallowfbcspnet-cnorm-adabn Acc: 0.6025\n",
      "Source: weibo2014 Target: eegbci shallowfbcspnet-tnorm-adabn Acc: 0.6118\n",
      "Source: weibo2014 Target: eegbci shallowfbcspnet-euclid-adabn Acc: 0.6389\n",
      "Source: weibo2014 Target: eegbci shallowfbcspnet-riemann-adabn Acc: 0.6347\n",
      "Source: weibo2014 Target: weibo2014 shallowfbcspnet-raw-adabn Acc: 0.7156\n",
      "Source: weibo2014 Target: weibo2014 shallowfbcspnet-cnorm-adabn Acc: 0.7061\n",
      "Source: weibo2014 Target: weibo2014 shallowfbcspnet-tnorm-adabn Acc: 0.7118\n",
      "Source: weibo2014 Target: weibo2014 shallowfbcspnet-euclid-adabn Acc: 0.7685\n",
      "Source: weibo2014 Target: weibo2014 shallowfbcspnet-riemann-adabn Acc: 0.7693\n",
      "Source: weibo2014 Target: cho2017 shallowfbcspnet-raw-adabn Acc: 0.5923\n",
      "Source: weibo2014 Target: cho2017 shallowfbcspnet-cnorm-adabn Acc: 0.5819\n",
      "Source: weibo2014 Target: cho2017 shallowfbcspnet-tnorm-adabn Acc: 0.5780\n",
      "Source: weibo2014 Target: cho2017 shallowfbcspnet-euclid-adabn Acc: 0.6355\n",
      "Source: weibo2014 Target: cho2017 shallowfbcspnet-riemann-adabn Acc: 0.6322\n",
      "Source: cho2017 Target: bnci2014001 shallowfbcspnet-raw-adabn Acc: 0.6557\n",
      "Source: cho2017 Target: bnci2014001 shallowfbcspnet-cnorm-adabn Acc: 0.6596\n",
      "Source: cho2017 Target: bnci2014001 shallowfbcspnet-tnorm-adabn Acc: 0.6517\n",
      "Source: cho2017 Target: bnci2014001 shallowfbcspnet-euclid-adabn Acc: 0.7177\n",
      "Source: cho2017 Target: bnci2014001 shallowfbcspnet-riemann-adabn Acc: 0.7196\n",
      "Source: cho2017 Target: eegbci shallowfbcspnet-raw-adabn Acc: 0.6271\n",
      "Source: cho2017 Target: eegbci shallowfbcspnet-cnorm-adabn Acc: 0.6128\n",
      "Source: cho2017 Target: eegbci shallowfbcspnet-tnorm-adabn Acc: 0.6214\n",
      "Source: cho2017 Target: eegbci shallowfbcspnet-euclid-adabn Acc: 0.6564\n",
      "Source: cho2017 Target: eegbci shallowfbcspnet-riemann-adabn Acc: 0.6540\n",
      "Source: cho2017 Target: weibo2014 shallowfbcspnet-raw-adabn Acc: 0.6818\n",
      "Source: cho2017 Target: weibo2014 shallowfbcspnet-cnorm-adabn Acc: 0.6896\n",
      "Source: cho2017 Target: weibo2014 shallowfbcspnet-tnorm-adabn Acc: 0.6724\n",
      "Source: cho2017 Target: weibo2014 shallowfbcspnet-euclid-adabn Acc: 0.7466\n",
      "Source: cho2017 Target: weibo2014 shallowfbcspnet-riemann-adabn Acc: 0.7463\n",
      "Source: cho2017 Target: cho2017 shallowfbcspnet-raw-adabn Acc: 0.7071\n",
      "Source: cho2017 Target: cho2017 shallowfbcspnet-cnorm-adabn Acc: 0.6856\n",
      "Source: cho2017 Target: cho2017 shallowfbcspnet-tnorm-adabn Acc: 0.7027\n",
      "Source: cho2017 Target: cho2017 shallowfbcspnet-euclid-adabn Acc: 0.7054\n",
      "Source: cho2017 Target: cho2017 shallowfbcspnet-riemann-adabn Acc: 0.7013\n",
      "Source: bnci2014001 Target: bnci2014001 eegnetv4-raw-adabn Acc: 0.8712\n",
      "Source: bnci2014001 Target: bnci2014001 eegnetv4-cnorm-adabn Acc: 0.8682\n",
      "Source: bnci2014001 Target: bnci2014001 eegnetv4-tnorm-adabn Acc: 0.8758\n",
      "Source: bnci2014001 Target: bnci2014001 eegnetv4-euclid-adabn Acc: 0.8839\n",
      "Source: bnci2014001 Target: bnci2014001 eegnetv4-riemann-adabn Acc: 0.8786\n",
      "Source: bnci2014001 Target: eegbci eegnetv4-raw-adabn Acc: 0.6538\n",
      "Source: bnci2014001 Target: eegbci eegnetv4-cnorm-adabn Acc: 0.6489\n",
      "Source: bnci2014001 Target: eegbci eegnetv4-tnorm-adabn Acc: 0.6576\n",
      "Source: bnci2014001 Target: eegbci eegnetv4-euclid-adabn Acc: 0.6597\n",
      "Source: bnci2014001 Target: eegbci eegnetv4-riemann-adabn Acc: 0.6569\n",
      "Source: bnci2014001 Target: weibo2014 eegnetv4-raw-adabn Acc: 0.6362\n",
      "Source: bnci2014001 Target: weibo2014 eegnetv4-cnorm-adabn Acc: 0.6385\n",
      "Source: bnci2014001 Target: weibo2014 eegnetv4-tnorm-adabn Acc: 0.6450\n",
      "Source: bnci2014001 Target: weibo2014 eegnetv4-euclid-adabn Acc: 0.6601\n",
      "Source: bnci2014001 Target: weibo2014 eegnetv4-riemann-adabn Acc: 0.6738\n",
      "Source: bnci2014001 Target: cho2017 eegnetv4-raw-adabn Acc: 0.5947\n",
      "Source: bnci2014001 Target: cho2017 eegnetv4-cnorm-adabn Acc: 0.5823\n",
      "Source: bnci2014001 Target: cho2017 eegnetv4-tnorm-adabn Acc: 0.5931\n",
      "Source: bnci2014001 Target: cho2017 eegnetv4-euclid-adabn Acc: 0.5894\n",
      "Source: bnci2014001 Target: cho2017 eegnetv4-riemann-adabn Acc: 0.5870\n",
      "Source: eegbci Target: bnci2014001 eegnetv4-raw-adabn Acc: 0.7689\n",
      "Source: eegbci Target: bnci2014001 eegnetv4-cnorm-adabn Acc: 0.7526\n",
      "Source: eegbci Target: bnci2014001 eegnetv4-tnorm-adabn Acc: 0.7539\n",
      "Source: eegbci Target: bnci2014001 eegnetv4-euclid-adabn Acc: 0.7883\n",
      "Source: eegbci Target: bnci2014001 eegnetv4-riemann-adabn Acc: 0.7867\n",
      "Source: eegbci Target: eegbci eegnetv4-raw-adabn Acc: 0.7085\n",
      "Source: eegbci Target: eegbci eegnetv4-cnorm-adabn Acc: 0.7053\n",
      "Source: eegbci Target: eegbci eegnetv4-tnorm-adabn Acc: 0.7050\n",
      "Source: eegbci Target: eegbci eegnetv4-euclid-adabn Acc: 0.7311\n",
      "Source: eegbci Target: eegbci eegnetv4-riemann-adabn Acc: 0.7237\n",
      "Source: eegbci Target: weibo2014 eegnetv4-raw-adabn Acc: 0.6534\n",
      "Source: eegbci Target: weibo2014 eegnetv4-cnorm-adabn Acc: 0.6448\n",
      "Source: eegbci Target: weibo2014 eegnetv4-tnorm-adabn Acc: 0.6604\n",
      "Source: eegbci Target: weibo2014 eegnetv4-euclid-adabn Acc: 0.7051\n",
      "Source: eegbci Target: weibo2014 eegnetv4-riemann-adabn Acc: 0.7054\n",
      "Source: eegbci Target: cho2017 eegnetv4-raw-adabn Acc: 0.6021\n",
      "Source: eegbci Target: cho2017 eegnetv4-cnorm-adabn Acc: 0.5806\n",
      "Source: eegbci Target: cho2017 eegnetv4-tnorm-adabn Acc: 0.6038\n",
      "Source: eegbci Target: cho2017 eegnetv4-euclid-adabn Acc: 0.6336\n",
      "Source: eegbci Target: cho2017 eegnetv4-riemann-adabn Acc: 0.6244\n",
      "Source: weibo2014 Target: bnci2014001 eegnetv4-raw-adabn Acc: 0.6660\n",
      "Source: weibo2014 Target: bnci2014001 eegnetv4-cnorm-adabn Acc: 0.6717\n",
      "Source: weibo2014 Target: bnci2014001 eegnetv4-tnorm-adabn Acc: 0.6798\n",
      "Source: weibo2014 Target: bnci2014001 eegnetv4-euclid-adabn Acc: 0.6980\n",
      "Source: weibo2014 Target: bnci2014001 eegnetv4-riemann-adabn Acc: 0.6880\n",
      "Source: weibo2014 Target: eegbci eegnetv4-raw-adabn Acc: 0.6268\n",
      "Source: weibo2014 Target: eegbci eegnetv4-cnorm-adabn Acc: 0.6185\n",
      "Source: weibo2014 Target: eegbci eegnetv4-tnorm-adabn Acc: 0.6292\n",
      "Source: weibo2014 Target: eegbci eegnetv4-euclid-adabn Acc: 0.6337\n",
      "Source: weibo2014 Target: eegbci eegnetv4-riemann-adabn Acc: 0.6396\n",
      "Source: weibo2014 Target: weibo2014 eegnetv4-raw-adabn Acc: 0.7301\n",
      "Source: weibo2014 Target: weibo2014 eegnetv4-cnorm-adabn Acc: 0.7346\n",
      "Source: weibo2014 Target: weibo2014 eegnetv4-tnorm-adabn Acc: 0.7303\n",
      "Source: weibo2014 Target: weibo2014 eegnetv4-euclid-adabn Acc: 0.7661\n",
      "Source: weibo2014 Target: weibo2014 eegnetv4-riemann-adabn Acc: 0.7669\n",
      "Source: weibo2014 Target: cho2017 eegnetv4-raw-adabn Acc: 0.6177\n",
      "Source: weibo2014 Target: cho2017 eegnetv4-cnorm-adabn Acc: 0.6062\n",
      "Source: weibo2014 Target: cho2017 eegnetv4-tnorm-adabn Acc: 0.6286\n",
      "Source: weibo2014 Target: cho2017 eegnetv4-euclid-adabn Acc: 0.6358\n",
      "Source: weibo2014 Target: cho2017 eegnetv4-riemann-adabn Acc: 0.6322\n",
      "Source: cho2017 Target: bnci2014001 eegnetv4-raw-adabn Acc: 0.6867\n",
      "Source: cho2017 Target: bnci2014001 eegnetv4-cnorm-adabn Acc: 0.6762\n",
      "Source: cho2017 Target: bnci2014001 eegnetv4-tnorm-adabn Acc: 0.6855\n",
      "Source: cho2017 Target: bnci2014001 eegnetv4-euclid-adabn Acc: 0.7083\n",
      "Source: cho2017 Target: bnci2014001 eegnetv4-riemann-adabn Acc: 0.7067\n",
      "Source: cho2017 Target: eegbci eegnetv4-raw-adabn Acc: 0.6424\n",
      "Source: cho2017 Target: eegbci eegnetv4-cnorm-adabn Acc: 0.6288\n",
      "Source: cho2017 Target: eegbci eegnetv4-tnorm-adabn Acc: 0.6442\n",
      "Source: cho2017 Target: eegbci eegnetv4-euclid-adabn Acc: 0.6695\n",
      "Source: cho2017 Target: eegbci eegnetv4-riemann-adabn Acc: 0.6683\n",
      "Source: cho2017 Target: weibo2014 eegnetv4-raw-adabn Acc: 0.6923\n",
      "Source: cho2017 Target: weibo2014 eegnetv4-cnorm-adabn Acc: 0.6831\n",
      "Source: cho2017 Target: weibo2014 eegnetv4-tnorm-adabn Acc: 0.6973\n",
      "Source: cho2017 Target: weibo2014 eegnetv4-euclid-adabn Acc: 0.7425\n",
      "Source: cho2017 Target: weibo2014 eegnetv4-riemann-adabn Acc: 0.7265\n",
      "Source: cho2017 Target: cho2017 eegnetv4-raw-adabn Acc: 0.7219\n",
      "Source: cho2017 Target: cho2017 eegnetv4-cnorm-adabn Acc: 0.7032\n",
      "Source: cho2017 Target: cho2017 eegnetv4-tnorm-adabn Acc: 0.7159\n",
      "Source: cho2017 Target: cho2017 eegnetv4-euclid-adabn Acc: 0.7307\n",
      "Source: cho2017 Target: cho2017 eegnetv4-riemann-adabn Acc: 0.7279\n",
      "Source: bnci2014001 Target: bnci2014001 tidnet-raw-adabn Acc: 0.6138\n",
      "Source: bnci2014001 Target: bnci2014001 tidnet-cnorm-adabn Acc: 0.5635\n",
      "Source: bnci2014001 Target: bnci2014001 tidnet-tnorm-adabn Acc: 0.6069\n",
      "Source: bnci2014001 Target: bnci2014001 tidnet-euclid-adabn Acc: 0.7807\n",
      "Source: bnci2014001 Target: bnci2014001 tidnet-riemann-adabn Acc: 0.7918\n",
      "Source: bnci2014001 Target: eegbci tidnet-raw-adabn Acc: 0.5433\n",
      "Source: bnci2014001 Target: eegbci tidnet-cnorm-adabn Acc: 0.5248\n",
      "Source: bnci2014001 Target: eegbci tidnet-tnorm-adabn Acc: 0.5428\n",
      "Source: bnci2014001 Target: eegbci tidnet-euclid-adabn Acc: 0.6416\n",
      "Source: bnci2014001 Target: eegbci tidnet-riemann-adabn Acc: 0.6438\n",
      "Source: bnci2014001 Target: weibo2014 tidnet-raw-adabn Acc: 0.5694\n",
      "Source: bnci2014001 Target: weibo2014 tidnet-cnorm-adabn Acc: 0.5243\n",
      "Source: bnci2014001 Target: weibo2014 tidnet-tnorm-adabn Acc: 0.5668\n",
      "Source: bnci2014001 Target: weibo2014 tidnet-euclid-adabn Acc: 0.6421\n",
      "Source: bnci2014001 Target: weibo2014 tidnet-riemann-adabn Acc: 0.6483\n",
      "Source: bnci2014001 Target: cho2017 tidnet-raw-adabn Acc: 0.5121\n",
      "Source: bnci2014001 Target: cho2017 tidnet-cnorm-adabn Acc: 0.4976\n",
      "Source: bnci2014001 Target: cho2017 tidnet-tnorm-adabn Acc: 0.5156\n",
      "Source: bnci2014001 Target: cho2017 tidnet-euclid-adabn Acc: 0.5516\n",
      "Source: bnci2014001 Target: cho2017 tidnet-riemann-adabn Acc: 0.5564\n",
      "Source: eegbci Target: bnci2014001 tidnet-raw-adabn Acc: 0.5496\n",
      "Source: eegbci Target: bnci2014001 tidnet-cnorm-adabn Acc: 0.5229\n",
      "Source: eegbci Target: bnci2014001 tidnet-tnorm-adabn Acc: 0.5533\n",
      "Source: eegbci Target: bnci2014001 tidnet-euclid-adabn Acc: 0.6778\n",
      "Source: eegbci Target: bnci2014001 tidnet-riemann-adabn Acc: 0.6773\n",
      "Source: eegbci Target: eegbci tidnet-raw-adabn Acc: 0.5522\n",
      "Source: eegbci Target: eegbci tidnet-cnorm-adabn Acc: 0.5301\n",
      "Source: eegbci Target: eegbci tidnet-tnorm-adabn Acc: 0.5611\n",
      "Source: eegbci Target: eegbci tidnet-euclid-adabn Acc: 0.6292\n",
      "Source: eegbci Target: eegbci tidnet-riemann-adabn Acc: 0.6201\n",
      "Source: eegbci Target: weibo2014 tidnet-raw-adabn Acc: 0.5458\n",
      "Source: eegbci Target: weibo2014 tidnet-cnorm-adabn Acc: 0.5147\n",
      "Source: eegbci Target: weibo2014 tidnet-tnorm-adabn Acc: 0.5501\n",
      "Source: eegbci Target: weibo2014 tidnet-euclid-adabn Acc: 0.6208\n",
      "Source: eegbci Target: weibo2014 tidnet-riemann-adabn Acc: 0.6278\n",
      "Source: eegbci Target: cho2017 tidnet-raw-adabn Acc: 0.5138\n",
      "Source: eegbci Target: cho2017 tidnet-cnorm-adabn Acc: 0.5115\n",
      "Source: eegbci Target: cho2017 tidnet-tnorm-adabn Acc: 0.5202\n",
      "Source: eegbci Target: cho2017 tidnet-euclid-adabn Acc: 0.5538\n",
      "Source: eegbci Target: cho2017 tidnet-riemann-adabn Acc: 0.5535\n",
      "Source: weibo2014 Target: bnci2014001 tidnet-raw-adabn Acc: 0.5577\n",
      "Source: weibo2014 Target: bnci2014001 tidnet-cnorm-adabn Acc: 0.5160\n",
      "Source: weibo2014 Target: bnci2014001 tidnet-tnorm-adabn Acc: 0.5520\n",
      "Source: weibo2014 Target: bnci2014001 tidnet-euclid-adabn Acc: 0.6472\n",
      "Source: weibo2014 Target: bnci2014001 tidnet-riemann-adabn Acc: 0.6408\n",
      "Source: weibo2014 Target: eegbci tidnet-raw-adabn Acc: 0.5448\n",
      "Source: weibo2014 Target: eegbci tidnet-cnorm-adabn Acc: 0.5043\n",
      "Source: weibo2014 Target: eegbci tidnet-tnorm-adabn Acc: 0.5443\n",
      "Source: weibo2014 Target: eegbci tidnet-euclid-adabn Acc: 0.5939\n",
      "Source: weibo2014 Target: eegbci tidnet-riemann-adabn Acc: 0.5884\n",
      "Source: weibo2014 Target: weibo2014 tidnet-raw-adabn Acc: 0.6058\n",
      "Source: weibo2014 Target: weibo2014 tidnet-cnorm-adabn Acc: 0.5515\n",
      "Source: weibo2014 Target: weibo2014 tidnet-tnorm-adabn Acc: 0.5988\n",
      "Source: weibo2014 Target: weibo2014 tidnet-euclid-adabn Acc: 0.7091\n",
      "Source: weibo2014 Target: weibo2014 tidnet-riemann-adabn Acc: 0.6952\n",
      "Source: weibo2014 Target: cho2017 tidnet-raw-adabn Acc: 0.5178\n",
      "Source: weibo2014 Target: cho2017 tidnet-cnorm-adabn Acc: 0.5067\n",
      "Source: weibo2014 Target: cho2017 tidnet-tnorm-adabn Acc: 0.5242\n",
      "Source: weibo2014 Target: cho2017 tidnet-euclid-adabn Acc: 0.5761\n",
      "Source: weibo2014 Target: cho2017 tidnet-riemann-adabn Acc: 0.5771\n",
      "Source: cho2017 Target: bnci2014001 tidnet-raw-adabn Acc: 0.5154\n",
      "Source: cho2017 Target: bnci2014001 tidnet-cnorm-adabn Acc: 0.4947\n",
      "Source: cho2017 Target: bnci2014001 tidnet-tnorm-adabn Acc: 0.5029\n",
      "Source: cho2017 Target: bnci2014001 tidnet-euclid-adabn Acc: 0.6359\n",
      "Source: cho2017 Target: bnci2014001 tidnet-riemann-adabn Acc: 0.6394\n",
      "Source: cho2017 Target: eegbci tidnet-raw-adabn Acc: 0.5177\n",
      "Source: cho2017 Target: eegbci tidnet-cnorm-adabn Acc: 0.5075\n",
      "Source: cho2017 Target: eegbci tidnet-tnorm-adabn Acc: 0.5131\n",
      "Source: cho2017 Target: eegbci tidnet-euclid-adabn Acc: 0.5928\n",
      "Source: cho2017 Target: eegbci tidnet-riemann-adabn Acc: 0.5903\n",
      "Source: cho2017 Target: weibo2014 tidnet-raw-adabn Acc: 0.5191\n",
      "Source: cho2017 Target: weibo2014 tidnet-cnorm-adabn Acc: 0.5064\n",
      "Source: cho2017 Target: weibo2014 tidnet-tnorm-adabn Acc: 0.5184\n",
      "Source: cho2017 Target: weibo2014 tidnet-euclid-adabn Acc: 0.6712\n",
      "Source: cho2017 Target: weibo2014 tidnet-riemann-adabn Acc: 0.6722\n",
      "Source: cho2017 Target: cho2017 tidnet-raw-adabn Acc: 0.5422\n",
      "Source: cho2017 Target: cho2017 tidnet-cnorm-adabn Acc: 0.5225\n",
      "Source: cho2017 Target: cho2017 tidnet-tnorm-adabn Acc: 0.5406\n",
      "Source: cho2017 Target: cho2017 tidnet-euclid-adabn Acc: 0.6156\n",
      "Source: cho2017 Target: cho2017 tidnet-riemann-adabn Acc: 0.6175\n"
     ]
    }
   ],
   "source": [
    "srate = 128\n",
    "datasets = [BNCI2014001(), PhysionetMI(), Weibo2014(), Cho2017()]\n",
    "selected_channels = ['FZ', 'FC3', 'FC1', 'FCZ', 'FC2', 'FC4', 'C5', 'C3', 'C1', 'CZ', 'C2', 'C4', 'C6', 'CP3', 'CP1', 'CPZ', 'CP2', 'CP4', 'P1', 'PZ', 'P2', 'POZ']\n",
    "duration = 3 # seconds\n",
    "events = ['left_hand', 'right_hand']\n",
    "preprocess_methods = ['raw', 'cnorm', 'tnorm', 'euclid', 'riemann']\n",
    "kfold = 5\n",
    "\n",
    "model_names = ['shallownet', 'eegnet', 'shallowfbcspnet', 'eegnetv4', 'tidnet']\n",
    "for model_name in model_names:\n",
    "    for source_dataset in datasets:\n",
    "        for target_dataset in datasets:\n",
    "            cross_dataset_network_predict(\n",
    "                model_name, source_dataset, target_dataset, selected_channels, srate, duration, events,\n",
    "                kfold=kfold, \n",
    "                save_folder=model_name,\n",
    "                preprocess_methods=preprocess_methods,\n",
    "                use_adabn=True,\n",
    "                force_update=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fusing MEKT, alignment strategies, and AdaBN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Expand4D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Expand4D, self).__init__()\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return X.unsqueeze(1)\n",
    "\n",
    "def make_feature_extractor(model_name, model):\n",
    "    if model_name == 'eegnet':\n",
    "        fe = nn.Sequential(Expand4D(), *list(model.model.children())[:-1])\n",
    "    elif model_name == 'shallownet':\n",
    "        fe = nn.Sequential(Expand4D(), *list(model.model.children())[:-1])\n",
    "    elif model_name == 'shallowfbcspnet':\n",
    "        fe = nn.Sequential(*list(model.children())[:-3], nn.Flatten())\n",
    "    elif model_name == 'eegnetv4':\n",
    "        fe = nn.Sequential(*list(model.children())[:-4], nn.Flatten())\n",
    "    elif model_name == 'tidnet':\n",
    "        fe = nn.Sequential(model.dscnn)\n",
    "    return fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_dataset_fusing_predict(\n",
    "    model_name, source_dataset, target_dataset, selected_channels, srate, duration, events,\n",
    "    kfold=5,\n",
    "    save_folder='eegnet',\n",
    "    preprocess_methods=['raw'],\n",
    "    use_adabn=False,\n",
    "    force_update=False):\n",
    "    \n",
    "    for preprocess_method in preprocess_methods:\n",
    "        model_name_str = '{}-{}'.format(model_name, preprocess_method)\n",
    "        \n",
    "        model_file = os.path.join(\n",
    "            save_folder, \n",
    "            \"{}-{}-{}classes.joblib\".format(\n",
    "                source_dataset.dataset_code, \n",
    "                model_name_str, \n",
    "                len(events)))\n",
    "        \n",
    "        if use_adabn:\n",
    "            save_file = os.path.join(\n",
    "                save_folder,\n",
    "                \"{}->{}-{}-{}classes.joblib\".format(\n",
    "                    source_dataset.dataset_code,\n",
    "                    target_dataset.dataset_code,\n",
    "                    model_name_str+'-adabn-mekt',\n",
    "                    len(events)))\n",
    "        else:\n",
    "            save_file = os.path.join(\n",
    "                save_folder,\n",
    "                \"{}->{}-{}-{}classes.joblib\".format(\n",
    "                    source_dataset.dataset_code,\n",
    "                    target_dataset.dataset_code,\n",
    "                    model_name_str+'-mekt',\n",
    "                    len(events)))\n",
    "        \n",
    "        if not force_update and os.path.exists(save_file):\n",
    "            kfold_accs = joblib.load(save_file)['kfold_accs']\n",
    "            print(\"Source: {} Target: {} {} Acc: {:.4f}\".format(\n",
    "                source_dataset.dataset_code,\n",
    "                target_dataset.dataset_code,\n",
    "                model_name_str+'-adabn-mekt' if use_adabn else model_name_str+'-mekt',\n",
    "                np.mean(kfold_accs)))\n",
    "            continue\n",
    "            \n",
    "        start_t = source_dataset.events['left_hand'][1][0]\n",
    "        if start_t+ duration > source_dataset.events['left_hand'][1][1]:\n",
    "            print(\"Warning: the current dataset avaliable trial duration is not long enough.\")\n",
    "        paradigm = MotorImagery(\n",
    "            channels=selected_channels, \n",
    "            srate=srate, \n",
    "            intervals=[(start_t, start_t + duration)], \n",
    "            events=events)\n",
    "        event_id = [source_dataset.events[e][0] for e in events]\n",
    "        paradigm.register_raw_hook(raw_hook)\n",
    "\n",
    "        Xs, ys, metas = paradigm.get_data(\n",
    "            source_dataset, \n",
    "            subjects=source_dataset.subjects, \n",
    "            return_concat=True, \n",
    "            verbose=False)\n",
    "        ys = label_encoder(ys, event_id)\n",
    "        labels = np.unique(ys)\n",
    "\n",
    "        set_random_seeds(38)\n",
    "        indices = generate_kfold_indices(metas, kfold=kfold)\n",
    "            \n",
    "        model_states = joblib.load(model_file)['model_states']\n",
    "        \n",
    "        n_trials, n_channels, n_samples = Xs.shape\n",
    "        n_classes = len(labels)\n",
    "        x_dtype, y_dtype = torch.float, torch.long\n",
    "        \n",
    "        kfold_accs, kfold_cms = [], []\n",
    "\n",
    "        set_random_seeds(42)\n",
    "        for k in range(kfold):\n",
    "            model = make_model(model_name, n_channels, n_samples, n_classes)\n",
    "            model.load_state_dict(copy.deepcopy(model_states[k]))\n",
    "            fe = make_feature_extractor(model_name, model)\n",
    "            fe.eval()\n",
    "            \n",
    "            filterX = np.copy(Xs)\n",
    "            filterY = np.copy(ys)\n",
    "            filterX = preprocessing(filterX, metas, k, indices,\n",
    "                        method=preprocess_method,\n",
    "                        no_split=False)\n",
    "            train_ind, valid_ind, test_ind = match_kfold_indices(k, metas, indices)\n",
    "            train_ind = np.concatenate((train_ind, valid_ind))\n",
    "            trainX, trainy = filterX[train_ind], filterY[train_ind]\n",
    "            trainX = generate_tensors(trainX, dtype=x_dtype)\n",
    "            source_features = fe(trainX).detach().numpy()\n",
    "            \n",
    "            if use_adabn:\n",
    "                handles = []\n",
    "                for module in fe.modules():\n",
    "                    if 'BatchNorm' in module.__class__.__name__:\n",
    "                        handles.append(\n",
    "                            module.register_forward_pre_hook(batchnorm_pre_forward_hook))\n",
    "            \n",
    "            sub_accs, sub_cms = [], []\n",
    "            for sub_id in target_dataset.subjects:\n",
    "                start_t = target_dataset.events['left_hand'][1][0]\n",
    "                if start_t+ duration > target_dataset.events['left_hand'][1][1]:\n",
    "                    print(\"Warning: the current dataset avaliable trial duration is not long enough.\")\n",
    "                paradigm = MotorImagery(\n",
    "                    channels=selected_channels, \n",
    "                    srate=srate, \n",
    "                    intervals=[(start_t, start_t + duration)], \n",
    "                    events=events)\n",
    "                event_id = [target_dataset.events[e][0] for e in events]\n",
    "                paradigm.register_raw_hook(raw_hook)\n",
    "\n",
    "                Xt, yt, metat = paradigm.get_data(\n",
    "                    target_dataset, \n",
    "                    subjects=[sub_id], \n",
    "                    return_concat=True, \n",
    "                    verbose=False)\n",
    "                yt = label_encoder(yt, event_id)\n",
    "                \n",
    "                Xt = preprocessing(Xt, metat, None, None,\n",
    "                        method=preprocess_method, \n",
    "                        no_split=True)\n",
    "                \n",
    "                torch.cuda.empty_cache()\n",
    "                testX = generate_tensors(Xt, dtype=x_dtype)\n",
    "                target_features = fe(testX).detach().numpy()\n",
    "                \n",
    "                mekt = MEKT(rho=5)\n",
    "                sf, tf = mekt.fit_transform(source_features, trainy, target_features)\n",
    "                clf = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')\n",
    "                pred_labels = clf.fit(sf, trainy).predict(tf)\n",
    "                true_labels = yt\n",
    "                \n",
    "                cm = confusion_matrix(true_labels, pred_labels, labels=labels, normalize='true')\n",
    "                sub_accs.append(balanced_accuracy_score(true_labels, pred_labels))\n",
    "                sub_cms.append(cm)\n",
    "            kfold_accs.append(sub_accs)\n",
    "            kfold_cms.append(sub_cms)\n",
    "\n",
    "        print(\"Source: {} Target: {} {} Acc: {:.4f}\".format(\n",
    "            source_dataset.dataset_code,\n",
    "            target_dataset.dataset_code,\n",
    "            model_name_str+'-adabn-mekt' if use_adabn else model_name_str+'-mekt',\n",
    "            np.mean(kfold_accs)))\n",
    "        joblib.dump({\n",
    "            'kfold_accs': kfold_accs, 'kfold_cms': kfold_cms}, \n",
    "            save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: bnci2014001 Target: eegbci eegnet-euclid-adabn-mekt Acc: 0.6663\n",
      "Source: bnci2014001 Target: eegbci eegnet-riemann-adabn-mekt Acc: 0.6680\n",
      "Source: bnci2014001 Target: weibo2014 eegnet-euclid-adabn-mekt Acc: 0.7159\n",
      "Source: bnci2014001 Target: weibo2014 eegnet-riemann-adabn-mekt Acc: 0.7142\n",
      "Source: bnci2014001 Target: cho2017 eegnet-euclid-adabn-mekt Acc: 0.6077\n",
      "Source: bnci2014001 Target: cho2017 eegnet-riemann-adabn-mekt Acc: 0.6051\n",
      "Source: eegbci Target: bnci2014001 eegnet-euclid-adabn-mekt Acc: 0.7765\n",
      "Source: eegbci Target: bnci2014001 eegnet-riemann-adabn-mekt Acc: 0.7764\n",
      "Source: eegbci Target: weibo2014 eegnet-euclid-adabn-mekt Acc: 0.7247\n",
      "Source: eegbci Target: weibo2014 eegnet-riemann-adabn-mekt Acc: 0.7372\n",
      "Source: eegbci Target: cho2017 eegnet-euclid-adabn-mekt Acc: 0.6476\n",
      "Source: eegbci Target: cho2017 eegnet-riemann-adabn-mekt Acc: 0.6437\n",
      "Source: weibo2014 Target: bnci2014001 eegnet-euclid-adabn-mekt Acc: 0.7030\n",
      "Source: weibo2014 Target: bnci2014001 eegnet-riemann-adabn-mekt Acc: 0.7049\n",
      "Source: weibo2014 Target: eegbci eegnet-euclid-adabn-mekt Acc: 0.6459\n",
      "Source: weibo2014 Target: eegbci eegnet-riemann-adabn-mekt Acc: 0.6452\n",
      "Source: weibo2014 Target: cho2017 eegnet-euclid-adabn-mekt Acc: 0.6404\n",
      "Source: weibo2014 Target: cho2017 eegnet-riemann-adabn-mekt Acc: 0.6401\n",
      "Source: cho2017 Target: bnci2014001 eegnet-euclid-adabn-mekt Acc: 0.7015\n",
      "Source: cho2017 Target: bnci2014001 eegnet-riemann-adabn-mekt Acc: 0.7048\n",
      "Source: cho2017 Target: eegbci eegnet-euclid-adabn-mekt Acc: 0.6654\n",
      "Source: cho2017 Target: eegbci eegnet-riemann-adabn-mekt Acc: 0.6592\n",
      "Source: cho2017 Target: weibo2014 eegnet-euclid-adabn-mekt Acc: 0.7389\n",
      "Source: cho2017 Target: weibo2014 eegnet-riemann-adabn-mekt Acc: 0.7351\n",
      "Source: bnci2014001 Target: eegbci eegnetv4-euclid-adabn-mekt Acc: 0.6536\n",
      "Source: bnci2014001 Target: eegbci eegnetv4-riemann-adabn-mekt Acc: 0.6552\n",
      "Source: bnci2014001 Target: weibo2014 eegnetv4-euclid-adabn-mekt Acc: 0.6967\n",
      "Source: bnci2014001 Target: weibo2014 eegnetv4-riemann-adabn-mekt Acc: 0.7035\n",
      "Source: bnci2014001 Target: cho2017 eegnetv4-euclid-adabn-mekt Acc: 0.6066\n",
      "Source: bnci2014001 Target: cho2017 eegnetv4-riemann-adabn-mekt Acc: 0.6039\n",
      "Source: eegbci Target: bnci2014001 eegnetv4-euclid-adabn-mekt Acc: 0.7862\n",
      "Source: eegbci Target: bnci2014001 eegnetv4-riemann-adabn-mekt Acc: 0.7786\n",
      "Source: eegbci Target: weibo2014 eegnetv4-euclid-adabn-mekt Acc: 0.7309\n",
      "Source: eegbci Target: weibo2014 eegnetv4-riemann-adabn-mekt Acc: 0.7317\n",
      "Source: eegbci Target: cho2017 eegnetv4-euclid-adabn-mekt Acc: 0.6503\n",
      "Source: eegbci Target: cho2017 eegnetv4-riemann-adabn-mekt Acc: 0.6413\n",
      "Source: weibo2014 Target: bnci2014001 eegnetv4-euclid-adabn-mekt Acc: 0.7102\n",
      "Source: weibo2014 Target: bnci2014001 eegnetv4-riemann-adabn-mekt Acc: 0.6924\n",
      "Source: weibo2014 Target: eegbci eegnetv4-euclid-adabn-mekt Acc: 0.6460\n",
      "Source: weibo2014 Target: eegbci eegnetv4-riemann-adabn-mekt Acc: 0.6445\n",
      "Source: weibo2014 Target: cho2017 eegnetv4-euclid-adabn-mekt Acc: 0.6417\n",
      "Source: weibo2014 Target: cho2017 eegnetv4-riemann-adabn-mekt Acc: 0.6351\n",
      "Source: cho2017 Target: bnci2014001 eegnetv4-euclid-adabn-mekt Acc: 0.7154\n",
      "Source: cho2017 Target: bnci2014001 eegnetv4-riemann-adabn-mekt Acc: 0.7221\n",
      "Source: cho2017 Target: eegbci eegnetv4-euclid-adabn-mekt Acc: 0.6789\n",
      "Source: cho2017 Target: eegbci eegnetv4-riemann-adabn-mekt Acc: 0.6733\n",
      "Source: cho2017 Target: weibo2014 eegnetv4-euclid-adabn-mekt Acc: 0.7528\n",
      "Source: cho2017 Target: weibo2014 eegnetv4-riemann-adabn-mekt Acc: 0.7407\n"
     ]
    }
   ],
   "source": [
    "srate = 128\n",
    "datasets = [BNCI2014001(), PhysionetMI(), Weibo2014(), Cho2017()]\n",
    "selected_channels = ['FZ', 'FC3', 'FC1', 'FCZ', 'FC2', 'FC4', 'C5', 'C3', 'C1', 'CZ', 'C2', 'C4', 'C6', 'CP3', 'CP1', 'CPZ', 'CP2', 'CP4', 'P1', 'PZ', 'P2', 'POZ']\n",
    "duration = 3 # seconds\n",
    "events = ['left_hand', 'right_hand']\n",
    "preprocess_methods = ['euclid', 'riemann']\n",
    "kfold = 5\n",
    "\n",
    "model_names = ['eegnet', 'eegnetv4']\n",
    "for model_name in model_names:\n",
    "    for source_dataset in datasets:\n",
    "        for target_dataset in datasets:\n",
    "            if source_dataset.dataset_code == target_dataset.dataset_code:\n",
    "                continue\n",
    "            cross_dataset_fusing_predict(\n",
    "                model_name, source_dataset, target_dataset, selected_channels, srate, duration, events,\n",
    "                kfold=kfold, \n",
    "                save_folder=model_name,\n",
    "                preprocess_methods=preprocess_methods,\n",
    "                use_adabn=True,\n",
    "                force_update=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
